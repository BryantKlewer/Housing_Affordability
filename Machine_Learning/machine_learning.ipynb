{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2 in c:\\users\\mattw\\anaconda3\\envs\\mlenv\\lib\\site-packages (2.9.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Dependencies\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import tensorflow as tf\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "from tensorflow import keras\n",
    "import datetime as dt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Housing Dataset\n",
    "---------------\n",
    "\n",
    "\n",
    "**Dataset characteristics:**\n",
    "\n",
    "    :Number of instances: 54,670\n",
    "\n",
    "    :Number of Attributes: 84\n",
    "\n",
    "    :Attribute Information:\n",
    " \n",
    "        -'Single_Family_Median_Typical_Home_Value' Median value of each house type\n",
    "        -'One_Bedroom_Median_Typical_Home_Value' Median value of one bedroom homes over the entire dataset\n",
    "        -'Two_Bedroom_Median_Typical_Home_Value' Median value of two bedroom homes over the entire dataset\n",
    "        -'Three_Bedroom_Median_Typical_Home_Value' Median value of three bedroom homes over the entire dataset\n",
    "        -'Four_Bedroom_Median_Typical_Home_Value' Median value of four bedroom homes over the entire dataset\n",
    "        -'Five_Plus_Bedroom_Median_Typical_Home_Value' Median value of five+ bedroom homes over the entire dataset\n",
    "        -'Estimated_Median_Household_Income' Median household income for the year for the city\n",
    "        -'2021_estimated_population' Estimated population for the city in 2021\n",
    "        -'Median_Taxes' Median taxes paid for the household in the city\n",
    "        -'Median_Rent' Median rent paid in the city for each year\n",
    "        -'Median_Monthly_Income' Median income divided by 12\n",
    "        -'Monthly_Affordability_Limit' Based on 30% of median monthly income\n",
    "        -'Year' The year each metric was observed\n",
    "        -'City_[CITYNAME]' Each city encoded using OneHotEncoder\n",
    "\n",
    "    :Missing Attribute Values: none\n",
    "\n",
    "This dataset was obtained from zillow research data and US census data from 2011 to 2021.\n",
    "\n",
    "The target variable for the confusion matrix is 'affordability_home_30yr_Payment_20_Perc_Down'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Identifier  City_Rank_by_Population(2021)       State State_abbreviation         City Observation_Date  Single_Family_Median_Typical_Home_Value  One_Bedroom_Median_Typical_Home_Value  Two_Bedroom_Median_Typical_Home_Value  Three_Bedroom_Median_Typical_Home_Value  ...  affordability_3br_30yr_Payment_10_Perc_Down  affordability_3br_30yr_Payment_20_Perc_Down  affordability_4br_15yr_Payment_10_Perc_Down  affordability_4br_15yr_Payment_20_Perc_Down  affordability_4br_30yr_Payment_10_Perc_Down  affordability_4br_30yr_Payment_20_Perc_Down  affordability_5_plus_br_15yr_Payment_10_Perc_Down  affordability_5_plus_br_15yr_Payment_20_Perc_Down  affordability_5_plus_br_30yr_Payment_10_Perc_Down  affordability_5_plus_br_30yr_Payment_20_Perc_Down\n",
      "0        201101                              1    New York                 NY     New York       2011-01-01                                 460824.0                               419555.5                               549450.5                                 455413.0  ...                                         0.60                                         0.67                                         0.36                                         0.40                                         0.51                                         0.58                                               0.29                                               0.32                                               0.41                                               0.46\n",
      "1        201201                              1    New York                 NY     New York       2012-01-01                                 453166.5                               421581.5                               549293.0                                 448447.0  ...                                         0.69                                         0.77                                         0.39                                         0.44                                         0.59                                         0.66                                               0.31                                               0.35                                               0.47                                               0.53\n",
      "2        201301                              1    New York                 NY     New York       2013-01-01                                 467125.5                               445182.5                               579800.5                                 461446.5  ...                                         0.66                                         0.74                                         0.38                                         0.43                                         0.56                                         0.63                                               0.30                                               0.34                                               0.44                                               0.50\n",
      "3        201401                              1    New York                 NY     New York       2014-01-01                                 499898.0                               487199.5                               634870.5                                 493995.0  ...                                         0.61                                         0.69                                         0.36                                         0.40                                         0.51                                         0.58                                               0.28                                               0.31                                               0.40                                               0.45\n",
      "4        201501                              1    New York                 NY     New York       2015-01-01                                 526189.0                               536285.0                               689511.5                                 522588.5  ...                                         0.63                                         0.71                                         0.36                                         0.40                                         0.53                                         0.59                                               0.27                                               0.30                                               0.40                                               0.45\n",
      "..          ...                            ...         ...                ...          ...              ...                                      ...                                    ...                                    ...                                      ...  ...                                          ...                                          ...                                          ...                                          ...                                          ...                                          ...                                                ...                                                ...                                                ...                                                ...\n",
      "776      201775                             75  New Jersey                 NJ  Jersey City       2017-01-01                                 408525.0                               471067.5                               537922.5                                 458794.5  ...                                         0.84                                         0.95                                         0.59                                         0.66                                         0.87                                         0.98                                               0.55                                               0.61                                               0.81                                               0.91\n",
      "777      201875                             75  New Jersey                 NJ  Jersey City       2018-01-01                                 459463.0                               503269.5                               568473.0                                 501645.0  ...                                         0.79                                         0.89                                         0.55                                         0.62                                         0.80                                         0.90                                               0.50                                               0.57                                               0.73                                               0.82\n",
      "778      201975                             75  New Jersey                 NJ  Jersey City       2019-01-01                                 489001.0                               490562.5                               566059.0                                 523939.5  ...                                         0.91                                         1.03                                         0.60                                         0.68                                         0.90                                         1.02                                               0.56                                               0.62                                               0.83                                               0.94\n",
      "779      202075                             75  New Jersey                 NJ  Jersey City       2020-01-01                                 514131.5                               487710.5                               570039.5                                 541306.0  ...                                         0.92                                         1.03                                         0.58                                         0.65                                         0.90                                         1.02                                               0.52                                               0.59                                               0.82                                               0.92\n",
      "780      202175                             75  New Jersey                 NJ  Jersey City       2021-01-01                                 569324.0                               502310.0                               594366.5                                 585132.5  ...                                         0.93                                         1.04                                         0.58                                         0.65                                         0.90                                         1.01                                               0.53                                               0.59                                               0.83                                               0.93\n",
      "\n",
      "[781 rows x 70 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import the dataset from the AWS database\n",
    "\n",
    "from config import engine_url\n",
    "\n",
    "# Create an engine instance\n",
    "\n",
    "alchemyEngine   = create_engine(engine_url, pool_recycle=3600);\n",
    "\n",
    " \n",
    "\n",
    "# Connect to PostgreSQL server\n",
    "\n",
    "dbConnection    = alchemyEngine.connect();\n",
    "\n",
    " \n",
    "\n",
    "# Read data from PostgreSQL database table and load into a DataFrame instance\n",
    "\n",
    "df       = pd.read_sql(\"select * from \\\"master_data_set\\\"\", dbConnection);\n",
    "\n",
    " \n",
    "\n",
    "pd.set_option('display.expand_frame_repr', False);\n",
    "\n",
    " \n",
    "\n",
    "# Print the DataFrame\n",
    "\n",
    "print(df);\n",
    "\n",
    " \n",
    "\n",
    "# Close the database connection\n",
    "\n",
    "dbConnection.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Identifier</th>\n",
       "      <th>City_Rank_by_Population(2021)</th>\n",
       "      <th>State</th>\n",
       "      <th>State_abbreviation</th>\n",
       "      <th>City</th>\n",
       "      <th>Observation_Date</th>\n",
       "      <th>Single_Family_Median_Typical_Home_Value</th>\n",
       "      <th>One_Bedroom_Median_Typical_Home_Value</th>\n",
       "      <th>Two_Bedroom_Median_Typical_Home_Value</th>\n",
       "      <th>Three_Bedroom_Median_Typical_Home_Value</th>\n",
       "      <th>...</th>\n",
       "      <th>affordability_3br_30yr_Payment_10_Perc_Down</th>\n",
       "      <th>affordability_3br_30yr_Payment_20_Perc_Down</th>\n",
       "      <th>affordability_4br_15yr_Payment_10_Perc_Down</th>\n",
       "      <th>affordability_4br_15yr_Payment_20_Perc_Down</th>\n",
       "      <th>affordability_4br_30yr_Payment_10_Perc_Down</th>\n",
       "      <th>affordability_4br_30yr_Payment_20_Perc_Down</th>\n",
       "      <th>affordability_5_plus_br_15yr_Payment_10_Perc_Down</th>\n",
       "      <th>affordability_5_plus_br_15yr_Payment_20_Perc_Down</th>\n",
       "      <th>affordability_5_plus_br_30yr_Payment_10_Perc_Down</th>\n",
       "      <th>affordability_5_plus_br_30yr_Payment_20_Perc_Down</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201101</td>\n",
       "      <td>1</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>460824.0</td>\n",
       "      <td>419555.5</td>\n",
       "      <td>549450.5</td>\n",
       "      <td>455413.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201201</td>\n",
       "      <td>1</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>453166.5</td>\n",
       "      <td>421581.5</td>\n",
       "      <td>549293.0</td>\n",
       "      <td>448447.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201301</td>\n",
       "      <td>1</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>467125.5</td>\n",
       "      <td>445182.5</td>\n",
       "      <td>579800.5</td>\n",
       "      <td>461446.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201401</td>\n",
       "      <td>1</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>499898.0</td>\n",
       "      <td>487199.5</td>\n",
       "      <td>634870.5</td>\n",
       "      <td>493995.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201501</td>\n",
       "      <td>1</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>526189.0</td>\n",
       "      <td>536285.0</td>\n",
       "      <td>689511.5</td>\n",
       "      <td>522588.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>201775</td>\n",
       "      <td>75</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>NJ</td>\n",
       "      <td>Jersey City</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>408525.0</td>\n",
       "      <td>471067.5</td>\n",
       "      <td>537922.5</td>\n",
       "      <td>458794.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>201875</td>\n",
       "      <td>75</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>NJ</td>\n",
       "      <td>Jersey City</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>459463.0</td>\n",
       "      <td>503269.5</td>\n",
       "      <td>568473.0</td>\n",
       "      <td>501645.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>201975</td>\n",
       "      <td>75</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>NJ</td>\n",
       "      <td>Jersey City</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>489001.0</td>\n",
       "      <td>490562.5</td>\n",
       "      <td>566059.0</td>\n",
       "      <td>523939.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>202075</td>\n",
       "      <td>75</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>NJ</td>\n",
       "      <td>Jersey City</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>514131.5</td>\n",
       "      <td>487710.5</td>\n",
       "      <td>570039.5</td>\n",
       "      <td>541306.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>202175</td>\n",
       "      <td>75</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>NJ</td>\n",
       "      <td>Jersey City</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>569324.0</td>\n",
       "      <td>502310.0</td>\n",
       "      <td>594366.5</td>\n",
       "      <td>585132.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>781 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Identifier  City_Rank_by_Population(2021)       State State_abbreviation         City Observation_Date  Single_Family_Median_Typical_Home_Value  One_Bedroom_Median_Typical_Home_Value  Two_Bedroom_Median_Typical_Home_Value  Three_Bedroom_Median_Typical_Home_Value  ...  affordability_3br_30yr_Payment_10_Perc_Down  affordability_3br_30yr_Payment_20_Perc_Down  affordability_4br_15yr_Payment_10_Perc_Down  affordability_4br_15yr_Payment_20_Perc_Down  affordability_4br_30yr_Payment_10_Perc_Down  affordability_4br_30yr_Payment_20_Perc_Down  affordability_5_plus_br_15yr_Payment_10_Perc_Down  affordability_5_plus_br_15yr_Payment_20_Perc_Down  affordability_5_plus_br_30yr_Payment_10_Perc_Down  affordability_5_plus_br_30yr_Payment_20_Perc_Down\n",
       "0        201101                              1    New York                 NY     New York       2011-01-01                                 460824.0                               419555.5                               549450.5                                 455413.0  ...                                         0.60                                         0.67                                         0.36                                         0.40                                         0.51                                         0.58                                               0.29                                               0.32                                               0.41                                               0.46\n",
       "1        201201                              1    New York                 NY     New York       2012-01-01                                 453166.5                               421581.5                               549293.0                                 448447.0  ...                                         0.69                                         0.77                                         0.39                                         0.44                                         0.59                                         0.66                                               0.31                                               0.35                                               0.47                                               0.53\n",
       "2        201301                              1    New York                 NY     New York       2013-01-01                                 467125.5                               445182.5                               579800.5                                 461446.5  ...                                         0.66                                         0.74                                         0.38                                         0.43                                         0.56                                         0.63                                               0.30                                               0.34                                               0.44                                               0.50\n",
       "3        201401                              1    New York                 NY     New York       2014-01-01                                 499898.0                               487199.5                               634870.5                                 493995.0  ...                                         0.61                                         0.69                                         0.36                                         0.40                                         0.51                                         0.58                                               0.28                                               0.31                                               0.40                                               0.45\n",
       "4        201501                              1    New York                 NY     New York       2015-01-01                                 526189.0                               536285.0                               689511.5                                 522588.5  ...                                         0.63                                         0.71                                         0.36                                         0.40                                         0.53                                         0.59                                               0.27                                               0.30                                               0.40                                               0.45\n",
       "..          ...                            ...         ...                ...          ...              ...                                      ...                                    ...                                    ...                                      ...  ...                                          ...                                          ...                                          ...                                          ...                                          ...                                          ...                                                ...                                                ...                                                ...                                                ...\n",
       "776      201775                             75  New Jersey                 NJ  Jersey City       2017-01-01                                 408525.0                               471067.5                               537922.5                                 458794.5  ...                                         0.84                                         0.95                                         0.59                                         0.66                                         0.87                                         0.98                                               0.55                                               0.61                                               0.81                                               0.91\n",
       "777      201875                             75  New Jersey                 NJ  Jersey City       2018-01-01                                 459463.0                               503269.5                               568473.0                                 501645.0  ...                                         0.79                                         0.89                                         0.55                                         0.62                                         0.80                                         0.90                                               0.50                                               0.57                                               0.73                                               0.82\n",
       "778      201975                             75  New Jersey                 NJ  Jersey City       2019-01-01                                 489001.0                               490562.5                               566059.0                                 523939.5  ...                                         0.91                                         1.03                                         0.60                                         0.68                                         0.90                                         1.02                                               0.56                                               0.62                                               0.83                                               0.94\n",
       "779      202075                             75  New Jersey                 NJ  Jersey City       2020-01-01                                 514131.5                               487710.5                               570039.5                                 541306.0  ...                                         0.92                                         1.03                                         0.58                                         0.65                                         0.90                                         1.02                                               0.52                                               0.59                                               0.82                                               0.92\n",
       "780      202175                             75  New Jersey                 NJ  Jersey City       2021-01-01                                 569324.0                               502310.0                               594366.5                                 585132.5  ...                                         0.93                                         1.04                                         0.58                                         0.65                                         0.90                                         1.01                                               0.53                                               0.59                                               0.83                                               0.93\n",
       "\n",
       "[781 rows x 70 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['affordability_rent',\n",
       " 'affordability_home_15yr_Payment_10_Perc_Down',\n",
       " 'affordability_home_15yr_Payment_20_Perc_Down',\n",
       " 'affordability_home_30yr_Payment_10_Perc_Down',\n",
       " 'affordability_home_30yr_Payment_20_Perc_Down',\n",
       " 'affordability_1br_15yr_Payment_10_Perc_Down',\n",
       " 'affordability_1br_15yr_Payment_20_Perc_Down',\n",
       " 'affordability_1br_30yr_Payment_10_Perc_Down',\n",
       " 'affordability_1br_30yr_Payment_20_Perc_Down',\n",
       " 'affordability_2br_15yr_Payment_10_Perc_Down',\n",
       " 'affordability_2br_15yr_Payment_20_Perc_Down',\n",
       " 'affordability_2br_30yr_Payment_10_Perc_Down',\n",
       " 'affordability_2br_30yr_Payment_20_Perc_Down',\n",
       " 'affordability_3br_15yr_Payment_10_Perc_Down',\n",
       " 'affordability_3br_15yr_Payment_20_Perc_Down',\n",
       " 'affordability_3br_30yr_Payment_10_Perc_Down',\n",
       " 'affordability_3br_30yr_Payment_20_Perc_Down',\n",
       " 'affordability_4br_15yr_Payment_10_Perc_Down',\n",
       " 'affordability_4br_15yr_Payment_20_Perc_Down',\n",
       " 'affordability_4br_30yr_Payment_10_Perc_Down',\n",
       " 'affordability_4br_30yr_Payment_20_Perc_Down',\n",
       " 'affordability_5_plus_br_15yr_Payment_10_Perc_Down',\n",
       " 'affordability_5_plus_br_15yr_Payment_20_Perc_Down',\n",
       " 'affordability_5_plus_br_30yr_Payment_10_Perc_Down',\n",
       " 'affordability_5_plus_br_30yr_Payment_20_Perc_Down']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of targets for the neural network\n",
    "\n",
    "columns_list = df.columns.to_list()\n",
    "\n",
    "target_list = columns_list[45:]\n",
    "\n",
    "target_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Identifier</th>\n",
       "      <th>City_Rank_by_Population(2021)</th>\n",
       "      <th>State</th>\n",
       "      <th>State_abbreviation</th>\n",
       "      <th>City</th>\n",
       "      <th>Observation_Date</th>\n",
       "      <th>Single_Family_Median_Typical_Home_Value</th>\n",
       "      <th>One_Bedroom_Median_Typical_Home_Value</th>\n",
       "      <th>Two_Bedroom_Median_Typical_Home_Value</th>\n",
       "      <th>Three_Bedroom_Median_Typical_Home_Value</th>\n",
       "      <th>...</th>\n",
       "      <th>affordability_3br_30yr_Payment_10_Perc_Down</th>\n",
       "      <th>affordability_3br_30yr_Payment_20_Perc_Down</th>\n",
       "      <th>affordability_4br_15yr_Payment_10_Perc_Down</th>\n",
       "      <th>affordability_4br_15yr_Payment_20_Perc_Down</th>\n",
       "      <th>affordability_4br_30yr_Payment_10_Perc_Down</th>\n",
       "      <th>affordability_4br_30yr_Payment_20_Perc_Down</th>\n",
       "      <th>affordability_5_plus_br_15yr_Payment_10_Perc_Down</th>\n",
       "      <th>affordability_5_plus_br_15yr_Payment_20_Perc_Down</th>\n",
       "      <th>affordability_5_plus_br_30yr_Payment_10_Perc_Down</th>\n",
       "      <th>affordability_5_plus_br_30yr_Payment_20_Perc_Down</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201101</td>\n",
       "      <td>1</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>460824.0</td>\n",
       "      <td>419555.5</td>\n",
       "      <td>549450.5</td>\n",
       "      <td>455413.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201201</td>\n",
       "      <td>1</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>453166.5</td>\n",
       "      <td>421581.5</td>\n",
       "      <td>549293.0</td>\n",
       "      <td>448447.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201301</td>\n",
       "      <td>1</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>467125.5</td>\n",
       "      <td>445182.5</td>\n",
       "      <td>579800.5</td>\n",
       "      <td>461446.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201401</td>\n",
       "      <td>1</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>499898.0</td>\n",
       "      <td>487199.5</td>\n",
       "      <td>634870.5</td>\n",
       "      <td>493995.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201501</td>\n",
       "      <td>1</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>526189.0</td>\n",
       "      <td>536285.0</td>\n",
       "      <td>689511.5</td>\n",
       "      <td>522588.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>201775</td>\n",
       "      <td>75</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>NJ</td>\n",
       "      <td>Jersey City</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>408525.0</td>\n",
       "      <td>471067.5</td>\n",
       "      <td>537922.5</td>\n",
       "      <td>458794.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>201875</td>\n",
       "      <td>75</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>NJ</td>\n",
       "      <td>Jersey City</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>459463.0</td>\n",
       "      <td>503269.5</td>\n",
       "      <td>568473.0</td>\n",
       "      <td>501645.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>201975</td>\n",
       "      <td>75</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>NJ</td>\n",
       "      <td>Jersey City</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>489001.0</td>\n",
       "      <td>490562.5</td>\n",
       "      <td>566059.0</td>\n",
       "      <td>523939.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>202075</td>\n",
       "      <td>75</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>NJ</td>\n",
       "      <td>Jersey City</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>514131.5</td>\n",
       "      <td>487710.5</td>\n",
       "      <td>570039.5</td>\n",
       "      <td>541306.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>202175</td>\n",
       "      <td>75</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>NJ</td>\n",
       "      <td>Jersey City</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>569324.0</td>\n",
       "      <td>502310.0</td>\n",
       "      <td>594366.5</td>\n",
       "      <td>585132.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>781 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Identifier  City_Rank_by_Population(2021)       State State_abbreviation         City Observation_Date  Single_Family_Median_Typical_Home_Value  One_Bedroom_Median_Typical_Home_Value  Two_Bedroom_Median_Typical_Home_Value  Three_Bedroom_Median_Typical_Home_Value  ...  affordability_3br_30yr_Payment_10_Perc_Down  affordability_3br_30yr_Payment_20_Perc_Down  affordability_4br_15yr_Payment_10_Perc_Down  affordability_4br_15yr_Payment_20_Perc_Down  affordability_4br_30yr_Payment_10_Perc_Down  affordability_4br_30yr_Payment_20_Perc_Down  affordability_5_plus_br_15yr_Payment_10_Perc_Down  affordability_5_plus_br_15yr_Payment_20_Perc_Down  affordability_5_plus_br_30yr_Payment_10_Perc_Down  affordability_5_plus_br_30yr_Payment_20_Perc_Down\n",
       "0        201101                              1    New York                 NY     New York       2011-01-01                                 460824.0                               419555.5                               549450.5                                 455413.0  ...                                            0                                            0                                            0                                            0                                            0                                            0                                                  0                                                  0                                                  0                                                  0\n",
       "1        201201                              1    New York                 NY     New York       2012-01-01                                 453166.5                               421581.5                               549293.0                                 448447.0  ...                                            0                                            0                                            0                                            0                                            0                                            0                                                  0                                                  0                                                  0                                                  0\n",
       "2        201301                              1    New York                 NY     New York       2013-01-01                                 467125.5                               445182.5                               579800.5                                 461446.5  ...                                            0                                            0                                            0                                            0                                            0                                            0                                                  0                                                  0                                                  0                                                  0\n",
       "3        201401                              1    New York                 NY     New York       2014-01-01                                 499898.0                               487199.5                               634870.5                                 493995.0  ...                                            0                                            0                                            0                                            0                                            0                                            0                                                  0                                                  0                                                  0                                                  0\n",
       "4        201501                              1    New York                 NY     New York       2015-01-01                                 526189.0                               536285.0                               689511.5                                 522588.5  ...                                            0                                            0                                            0                                            0                                            0                                            0                                                  0                                                  0                                                  0                                                  0\n",
       "..          ...                            ...         ...                ...          ...              ...                                      ...                                    ...                                    ...                                      ...  ...                                          ...                                          ...                                          ...                                          ...                                          ...                                          ...                                                ...                                                ...                                                ...                                                ...\n",
       "776      201775                             75  New Jersey                 NJ  Jersey City       2017-01-01                                 408525.0                               471067.5                               537922.5                                 458794.5  ...                                            0                                            0                                            0                                            0                                            0                                            0                                                  0                                                  0                                                  0                                                  0\n",
       "777      201875                             75  New Jersey                 NJ  Jersey City       2018-01-01                                 459463.0                               503269.5                               568473.0                                 501645.0  ...                                            0                                            0                                            0                                            0                                            0                                            0                                                  0                                                  0                                                  0                                                  0\n",
       "778      201975                             75  New Jersey                 NJ  Jersey City       2019-01-01                                 489001.0                               490562.5                               566059.0                                 523939.5  ...                                            0                                            1                                            0                                            0                                            0                                            1                                                  0                                                  0                                                  0                                                  0\n",
       "779      202075                             75  New Jersey                 NJ  Jersey City       2020-01-01                                 514131.5                               487710.5                               570039.5                                 541306.0  ...                                            0                                            1                                            0                                            0                                            0                                            1                                                  0                                                  0                                                  0                                                  0\n",
       "780      202175                             75  New Jersey                 NJ  Jersey City       2021-01-01                                 569324.0                               502310.0                               594366.5                                 585132.5  ...                                            0                                            1                                            0                                            0                                            0                                            1                                                  0                                                  0                                                  0                                                  0\n",
       "\n",
       "[781 rows x 70 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change affordability to 0 or 1 in the target columns\n",
    "\n",
    "df[target_list] = np.where(df[target_list]>=1.00,1, 0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode each city into its own column\n",
    "\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "encode_df = pd.DataFrame(enc.fit_transform(df[['City']]))\n",
    "encode_df.columns=enc.get_feature_names_out(['City'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the encoded city columns and drop the City column\n",
    "\n",
    "df = df.merge(encode_df, left_index=True, right_index=True)\n",
    "df.drop(columns=['City'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the observation date to year\n",
    "\n",
    "df['Observation_Date'] = pd.to_datetime(df['Observation_Date'])\n",
    "df['Year'] = df['Observation_Date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Identifier</th>\n",
       "      <th>City_Rank_by_Population(2021)</th>\n",
       "      <th>State</th>\n",
       "      <th>State_abbreviation</th>\n",
       "      <th>Observation_Date</th>\n",
       "      <th>Single_Family_Median_Typical_Home_Value</th>\n",
       "      <th>One_Bedroom_Median_Typical_Home_Value</th>\n",
       "      <th>Two_Bedroom_Median_Typical_Home_Value</th>\n",
       "      <th>Three_Bedroom_Median_Typical_Home_Value</th>\n",
       "      <th>Four_Bedroom_Median_Typical_Home_Value</th>\n",
       "      <th>...</th>\n",
       "      <th>City_Santa Ana</th>\n",
       "      <th>City_Seattle</th>\n",
       "      <th>City_Stockton</th>\n",
       "      <th>City_Tampa</th>\n",
       "      <th>City_Tucson</th>\n",
       "      <th>City_Tulsa</th>\n",
       "      <th>City_Virginia Beach</th>\n",
       "      <th>City_Washington</th>\n",
       "      <th>City_Wichita</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>202101</td>\n",
       "      <td>1</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>706417.0</td>\n",
       "      <td>603709.0</td>\n",
       "      <td>751189.0</td>\n",
       "      <td>690397.5</td>\n",
       "      <td>829040.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>202102</td>\n",
       "      <td>2</td>\n",
       "      <td>California</td>\n",
       "      <td>CA</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>937656.5</td>\n",
       "      <td>575026.0</td>\n",
       "      <td>746089.5</td>\n",
       "      <td>860336.5</td>\n",
       "      <td>1066739.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>202103</td>\n",
       "      <td>3</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>IL</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>282580.0</td>\n",
       "      <td>236544.5</td>\n",
       "      <td>284521.5</td>\n",
       "      <td>291592.0</td>\n",
       "      <td>346520.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>202104</td>\n",
       "      <td>4</td>\n",
       "      <td>Texas</td>\n",
       "      <td>TX</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>229725.5</td>\n",
       "      <td>132536.0</td>\n",
       "      <td>168663.5</td>\n",
       "      <td>210146.0</td>\n",
       "      <td>276587.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>202105</td>\n",
       "      <td>5</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>AZ</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>359291.5</td>\n",
       "      <td>216523.0</td>\n",
       "      <td>277632.0</td>\n",
       "      <td>340718.0</td>\n",
       "      <td>428991.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>202171</td>\n",
       "      <td>71</td>\n",
       "      <td>Nebraska</td>\n",
       "      <td>NE</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>239984.0</td>\n",
       "      <td>202191.0</td>\n",
       "      <td>192750.0</td>\n",
       "      <td>240544.5</td>\n",
       "      <td>326178.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>202172</td>\n",
       "      <td>72</td>\n",
       "      <td>Texas</td>\n",
       "      <td>TX</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>418720.0</td>\n",
       "      <td>201140.5</td>\n",
       "      <td>291360.0</td>\n",
       "      <td>343630.0</td>\n",
       "      <td>460291.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>202173</td>\n",
       "      <td>73</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>AK</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>386293.5</td>\n",
       "      <td>182718.5</td>\n",
       "      <td>233835.5</td>\n",
       "      <td>348141.5</td>\n",
       "      <td>439046.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>202174</td>\n",
       "      <td>74</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>NC</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>314496.5</td>\n",
       "      <td>211638.0</td>\n",
       "      <td>229229.5</td>\n",
       "      <td>292391.5</td>\n",
       "      <td>406237.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>202175</td>\n",
       "      <td>75</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>NJ</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>569324.0</td>\n",
       "      <td>502310.0</td>\n",
       "      <td>594366.5</td>\n",
       "      <td>585132.5</td>\n",
       "      <td>602130.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71 rows × 141 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Identifier  City_Rank_by_Population(2021)           State State_abbreviation Observation_Date  Single_Family_Median_Typical_Home_Value  One_Bedroom_Median_Typical_Home_Value  Two_Bedroom_Median_Typical_Home_Value  Three_Bedroom_Median_Typical_Home_Value  Four_Bedroom_Median_Typical_Home_Value  ...  City_Santa Ana  City_Seattle  City_Stockton  City_Tampa  City_Tucson  City_Tulsa  City_Virginia Beach  City_Washington  City_Wichita  Year\n",
       "10       202101                              1        New York                 NY       2021-01-01                                 706417.0                               603709.0                               751189.0                                 690397.5                                829040.0  ...             0.0           0.0            0.0         0.0          0.0         0.0                  0.0              0.0           0.0  2021\n",
       "21       202102                              2      California                 CA       2021-01-01                                 937656.5                               575026.0                               746089.5                                 860336.5                               1066739.5  ...             0.0           0.0            0.0         0.0          0.0         0.0                  0.0              0.0           0.0  2021\n",
       "32       202103                              3        Illinois                 IL       2021-01-01                                 282580.0                               236544.5                               284521.5                                 291592.0                                346520.0  ...             0.0           0.0            0.0         0.0          0.0         0.0                  0.0              0.0           0.0  2021\n",
       "43       202104                              4           Texas                 TX       2021-01-01                                 229725.5                               132536.0                               168663.5                                 210146.0                                276587.5  ...             0.0           0.0            0.0         0.0          0.0         0.0                  0.0              0.0           0.0  2021\n",
       "54       202105                              5         Arizona                 AZ       2021-01-01                                 359291.5                               216523.0                               277632.0                                 340718.0                                428991.5  ...             0.0           0.0            0.0         0.0          0.0         0.0                  0.0              0.0           0.0  2021\n",
       "..          ...                            ...             ...                ...              ...                                      ...                                    ...                                    ...                                      ...                                     ...  ...             ...           ...            ...         ...          ...         ...                  ...              ...           ...   ...\n",
       "736      202171                             71        Nebraska                 NE       2021-01-01                                 239984.0                               202191.0                               192750.0                                 240544.5                                326178.5  ...             0.0           0.0            0.0         0.0          0.0         0.0                  0.0              0.0           0.0  2021\n",
       "747      202172                             72           Texas                 TX       2021-01-01                                 418720.0                               201140.5                               291360.0                                 343630.0                                460291.0  ...             0.0           0.0            0.0         0.0          0.0         0.0                  0.0              0.0           0.0  2021\n",
       "758      202173                             73          Alaska                 AK       2021-01-01                                 386293.5                               182718.5                               233835.5                                 348141.5                                439046.0  ...             0.0           0.0            0.0         0.0          0.0         0.0                  0.0              0.0           0.0  2021\n",
       "769      202174                             74  North Carolina                 NC       2021-01-01                                 314496.5                               211638.0                               229229.5                                 292391.5                                406237.0  ...             0.0           0.0            0.0         0.0          0.0         0.0                  0.0              0.0           0.0  2021\n",
       "780      202175                             75      New Jersey                 NJ       2021-01-01                                 569324.0                               502310.0                               594366.5                                 585132.5                                602130.5  ...             0.0           0.0            0.0         0.0          0.0         0.0                  0.0              0.0           0.0  2021\n",
       "\n",
       "[71 rows x 141 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataset for 2021 to test the model's ability to predict affordability\n",
    "\n",
    "df_eval = df.loc[df['Year']==2021]\n",
    "df_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Identifier</th>\n",
       "      <th>City_Rank_by_Population(2021)</th>\n",
       "      <th>State</th>\n",
       "      <th>State_abbreviation</th>\n",
       "      <th>Observation_Date</th>\n",
       "      <th>Single_Family_Median_Typical_Home_Value</th>\n",
       "      <th>One_Bedroom_Median_Typical_Home_Value</th>\n",
       "      <th>Two_Bedroom_Median_Typical_Home_Value</th>\n",
       "      <th>Three_Bedroom_Median_Typical_Home_Value</th>\n",
       "      <th>Four_Bedroom_Median_Typical_Home_Value</th>\n",
       "      <th>...</th>\n",
       "      <th>City_Santa Ana</th>\n",
       "      <th>City_Seattle</th>\n",
       "      <th>City_Stockton</th>\n",
       "      <th>City_Tampa</th>\n",
       "      <th>City_Tucson</th>\n",
       "      <th>City_Tulsa</th>\n",
       "      <th>City_Virginia Beach</th>\n",
       "      <th>City_Washington</th>\n",
       "      <th>City_Wichita</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201101</td>\n",
       "      <td>1</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>460824.0</td>\n",
       "      <td>419555.5</td>\n",
       "      <td>549450.5</td>\n",
       "      <td>455413.0</td>\n",
       "      <td>532583.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201201</td>\n",
       "      <td>1</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>453166.5</td>\n",
       "      <td>421581.5</td>\n",
       "      <td>549293.0</td>\n",
       "      <td>448447.0</td>\n",
       "      <td>526229.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201301</td>\n",
       "      <td>1</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>467125.5</td>\n",
       "      <td>445182.5</td>\n",
       "      <td>579800.5</td>\n",
       "      <td>461446.5</td>\n",
       "      <td>543111.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201401</td>\n",
       "      <td>1</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>499898.0</td>\n",
       "      <td>487199.5</td>\n",
       "      <td>634870.5</td>\n",
       "      <td>493995.0</td>\n",
       "      <td>588659.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201501</td>\n",
       "      <td>1</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>526189.0</td>\n",
       "      <td>536285.0</td>\n",
       "      <td>689511.5</td>\n",
       "      <td>522588.5</td>\n",
       "      <td>628622.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>201675</td>\n",
       "      <td>75</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>NJ</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>365580.5</td>\n",
       "      <td>433664.0</td>\n",
       "      <td>495381.5</td>\n",
       "      <td>410903.0</td>\n",
       "      <td>403386.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>201775</td>\n",
       "      <td>75</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>NJ</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>408525.0</td>\n",
       "      <td>471067.5</td>\n",
       "      <td>537922.5</td>\n",
       "      <td>458794.5</td>\n",
       "      <td>445592.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>201875</td>\n",
       "      <td>75</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>NJ</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>459463.0</td>\n",
       "      <td>503269.5</td>\n",
       "      <td>568473.0</td>\n",
       "      <td>501645.0</td>\n",
       "      <td>497800.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>201975</td>\n",
       "      <td>75</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>NJ</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>489001.0</td>\n",
       "      <td>490562.5</td>\n",
       "      <td>566059.0</td>\n",
       "      <td>523939.5</td>\n",
       "      <td>529699.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>202075</td>\n",
       "      <td>75</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>NJ</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>514131.5</td>\n",
       "      <td>487710.5</td>\n",
       "      <td>570039.5</td>\n",
       "      <td>541306.0</td>\n",
       "      <td>548908.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>710 rows × 141 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Identifier  City_Rank_by_Population(2021)       State State_abbreviation Observation_Date  Single_Family_Median_Typical_Home_Value  One_Bedroom_Median_Typical_Home_Value  Two_Bedroom_Median_Typical_Home_Value  Three_Bedroom_Median_Typical_Home_Value  Four_Bedroom_Median_Typical_Home_Value  ...  City_Santa Ana  City_Seattle  City_Stockton  City_Tampa  City_Tucson  City_Tulsa  City_Virginia Beach  City_Washington  City_Wichita  Year\n",
       "0        201101                              1    New York                 NY       2011-01-01                                 460824.0                               419555.5                               549450.5                                 455413.0                                532583.5  ...             0.0           0.0            0.0         0.0          0.0         0.0                  0.0              0.0           0.0  2011\n",
       "1        201201                              1    New York                 NY       2012-01-01                                 453166.5                               421581.5                               549293.0                                 448447.0                                526229.0  ...             0.0           0.0            0.0         0.0          0.0         0.0                  0.0              0.0           0.0  2012\n",
       "2        201301                              1    New York                 NY       2013-01-01                                 467125.5                               445182.5                               579800.5                                 461446.5                                543111.5  ...             0.0           0.0            0.0         0.0          0.0         0.0                  0.0              0.0           0.0  2013\n",
       "3        201401                              1    New York                 NY       2014-01-01                                 499898.0                               487199.5                               634870.5                                 493995.0                                588659.0  ...             0.0           0.0            0.0         0.0          0.0         0.0                  0.0              0.0           0.0  2014\n",
       "4        201501                              1    New York                 NY       2015-01-01                                 526189.0                               536285.0                               689511.5                                 522588.5                                628622.0  ...             0.0           0.0            0.0         0.0          0.0         0.0                  0.0              0.0           0.0  2015\n",
       "..          ...                            ...         ...                ...              ...                                      ...                                    ...                                    ...                                      ...                                     ...  ...             ...           ...            ...         ...          ...         ...                  ...              ...           ...   ...\n",
       "775      201675                             75  New Jersey                 NJ       2016-01-01                                 365580.5                               433664.0                               495381.5                                 410903.0                                403386.5  ...             0.0           0.0            0.0         0.0          0.0         0.0                  0.0              0.0           0.0  2016\n",
       "776      201775                             75  New Jersey                 NJ       2017-01-01                                 408525.0                               471067.5                               537922.5                                 458794.5                                445592.0  ...             0.0           0.0            0.0         0.0          0.0         0.0                  0.0              0.0           0.0  2017\n",
       "777      201875                             75  New Jersey                 NJ       2018-01-01                                 459463.0                               503269.5                               568473.0                                 501645.0                                497800.5  ...             0.0           0.0            0.0         0.0          0.0         0.0                  0.0              0.0           0.0  2018\n",
       "778      201975                             75  New Jersey                 NJ       2019-01-01                                 489001.0                               490562.5                               566059.0                                 523939.5                                529699.5  ...             0.0           0.0            0.0         0.0          0.0         0.0                  0.0              0.0           0.0  2019\n",
       "779      202075                             75  New Jersey                 NJ       2020-01-01                                 514131.5                               487710.5                               570039.5                                 541306.0                                548908.0  ...             0.0           0.0            0.0         0.0          0.0         0.0                  0.0              0.0           0.0  2020\n",
       "\n",
       "[710 rows x 141 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataset from 2011-2020 to train the neural network\n",
    "\n",
    "df_train= df.loc[df['Year']!=2021]\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Single_Family_Median_Typical_Home_Value',\n",
       " 'One_Bedroom_Median_Typical_Home_Value',\n",
       " 'Two_Bedroom_Median_Typical_Home_Value',\n",
       " 'Three_Bedroom_Median_Typical_Home_Value',\n",
       " 'Four_Bedroom_Median_Typical_Home_Value',\n",
       " 'Five_Plus_Bedroom_Median_Typical_Home_Value',\n",
       " 'Estimated_Median_Household_Income',\n",
       " '2021_estimated_population',\n",
       " 'Median_Taxes',\n",
       " 'Median_Rent',\n",
       " 'Median_Monthly_Income',\n",
       " 'Monthly_Affordability_Limit',\n",
       " 'City_Albuquerque',\n",
       " 'City_Anaheim',\n",
       " 'City_Anchorage',\n",
       " 'City_Arlington',\n",
       " 'City_Atlanta',\n",
       " 'City_Aurora',\n",
       " 'City_Austin',\n",
       " 'City_Bakersfield',\n",
       " 'City_Baltimore',\n",
       " 'City_Boston',\n",
       " 'City_Charlotte',\n",
       " 'City_Chicago',\n",
       " 'City_Cincinnati',\n",
       " 'City_Cleveland',\n",
       " 'City_Colorado Springs',\n",
       " 'City_Columbus',\n",
       " 'City_Corpus Christi',\n",
       " 'City_Dallas',\n",
       " 'City_Denver',\n",
       " 'City_Detroit',\n",
       " 'City_Durham',\n",
       " 'City_El Paso',\n",
       " 'City_Fort Worth',\n",
       " 'City_Fresno',\n",
       " 'City_Greensboro',\n",
       " 'City_Henderson',\n",
       " 'City_Houston',\n",
       " 'City_Indianapolis',\n",
       " 'City_Irvine',\n",
       " 'City_Jacksonville',\n",
       " 'City_Jersey City',\n",
       " 'City_Kansas City',\n",
       " 'City_Las Vegas',\n",
       " 'City_Lincoln',\n",
       " 'City_Long Beach',\n",
       " 'City_Los Angeles',\n",
       " 'City_Memphis',\n",
       " 'City_Mesa',\n",
       " 'City_Miami',\n",
       " 'City_Milwaukee',\n",
       " 'City_Minneapolis',\n",
       " 'City_New Orleans',\n",
       " 'City_New York',\n",
       " 'City_Newark',\n",
       " 'City_Oakland',\n",
       " 'City_Oklahoma City',\n",
       " 'City_Omaha',\n",
       " 'City_Orlando',\n",
       " 'City_Philadelphia',\n",
       " 'City_Phoenix',\n",
       " 'City_Pittsburgh',\n",
       " 'City_Plano',\n",
       " 'City_Portland',\n",
       " 'City_Raleigh',\n",
       " 'City_Riverside',\n",
       " 'City_Sacramento',\n",
       " 'City_Saint Louis',\n",
       " 'City_Saint Paul',\n",
       " 'City_San Antonio',\n",
       " 'City_San Diego',\n",
       " 'City_San Francisco',\n",
       " 'City_San Jose',\n",
       " 'City_Santa Ana',\n",
       " 'City_Seattle',\n",
       " 'City_Stockton',\n",
       " 'City_Tampa',\n",
       " 'City_Tucson',\n",
       " 'City_Tulsa',\n",
       " 'City_Virginia Beach',\n",
       " 'City_Washington',\n",
       " 'City_Wichita',\n",
       " 'Year']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a list of features for the neural network\n",
    "\n",
    "columns_list = df.columns.tolist()\n",
    "columns_list\n",
    "\n",
    "remove_list = ['Identifier',\n",
    " 'City_Rank_by_Population(2021)',\n",
    " 'State',\n",
    " 'State_abbreviation',\n",
    " 'Observation_Date',\n",
    " '2020_census',\n",
    " 'AnnualAverageRate15Year',\n",
    " 'AnnualAverageRate30Year',\n",
    " 'home_15yr_Payment_10_Perc_Down',\n",
    " 'home_15yr_Payment_20_Perc_Down',\n",
    " 'home_30yr_Payment_10_Perc_Down',\n",
    " 'home_30yr_Payment_20_Perc_Down',\n",
    " '1br_15yr_Payment_10_Perc_Down',\n",
    " '1br_15yr_Payment_20_Perc_Down',\n",
    " '1br_30yr_Payment_10_Perc_Down',\n",
    " '1br_30yr_Payment_20_Perc_Down',\n",
    " '2br_15yr_Payment_10_Perc_Down',\n",
    " '2br_15yr_Payment_20_Perc_Down',\n",
    " '2br_30yr_Payment_10_Perc_Down',\n",
    " '2br_30yr_Payment_20_Perc_Down',\n",
    " '3br_15yr_Payment_10_Perc_Down',\n",
    " '3br_15yr_Payment_20_Perc_Down',\n",
    " '3br_30yr_Payment_10_Perc_Down',\n",
    " '3br_30yr_Payment_20_Perc_Down',\n",
    " '4br_15yr_Payment_10_Perc_Down',\n",
    " '4br_15yr_Payment_20_Perc_Down',\n",
    " '4br_30yr_Payment_10_Perc_Down',\n",
    " '4br_30yr_Payment_20_Perc_Down',\n",
    " '5_plus_br_15yr_Payment_10_Perc_Down',\n",
    " '5_plus_br_15yr_Payment_20_Perc_Down',\n",
    " '5_plus_br_30yr_Payment_10_Perc_Down',\n",
    " '5_plus_br_30yr_Payment_20_Perc_Down',\n",
    " 'affordability_rent',\n",
    " 'affordability_home_15yr_Payment_10_Perc_Down',\n",
    " 'affordability_home_15yr_Payment_20_Perc_Down',\n",
    " 'affordability_home_30yr_Payment_10_Perc_Down',\n",
    " 'affordability_home_30yr_Payment_20_Perc_Down',\n",
    " 'affordability_1br_15yr_Payment_10_Perc_Down',\n",
    " 'affordability_1br_15yr_Payment_20_Perc_Down',\n",
    " 'affordability_1br_30yr_Payment_10_Perc_Down',\n",
    " 'affordability_1br_30yr_Payment_20_Perc_Down',\n",
    " 'affordability_2br_15yr_Payment_10_Perc_Down',\n",
    " 'affordability_2br_15yr_Payment_20_Perc_Down',\n",
    " 'affordability_2br_30yr_Payment_10_Perc_Down',\n",
    " 'affordability_2br_30yr_Payment_20_Perc_Down',\n",
    " 'affordability_3br_15yr_Payment_10_Perc_Down',\n",
    " 'affordability_3br_15yr_Payment_20_Perc_Down',\n",
    " 'affordability_3br_30yr_Payment_10_Perc_Down',\n",
    " 'affordability_3br_30yr_Payment_20_Perc_Down',\n",
    " 'affordability_4br_15yr_Payment_10_Perc_Down',\n",
    " 'affordability_4br_15yr_Payment_20_Perc_Down',\n",
    " 'affordability_4br_30yr_Payment_10_Perc_Down',\n",
    " 'affordability_4br_30yr_Payment_20_Perc_Down',\n",
    " 'affordability_5_plus_br_15yr_Payment_10_Perc_Down',\n",
    " 'affordability_5_plus_br_15yr_Payment_20_Perc_Down',\n",
    " 'affordability_5_plus_br_30yr_Payment_10_Perc_Down',\n",
    " 'affordability_5_plus_br_30yr_Payment_20_Perc_Down']\n",
    "\n",
    "for metric in remove_list:\n",
    "    columns_list.remove(metric)\n",
    "\n",
    "columns_list\n",
    "\n",
    "# x_columns = ['Year','Estimated_Median_Household_Income', '2021_estimated_population', '2020_census', 'Median_Taxes', 'Median_Rent', 'AnnualAverageRate30Year','Median_Monthly_Income','Monthly_Affordability_Limit'] \n",
    "# 'home_30yr_Payment_20_Perc_Down', '1br_30yr_Payment_20_Perc_Down', '2br_30yr_Payment_20_Perc_Down', \n",
    "# '3br_30yr_Payment_20_Perc_Down', '4br_30yr_Payment_20_Perc_Down', '5_plus_br_30yr_Payment_20_Perc_Down', 'Median_Monthly_Income', 'Monthly_Affordability_Limit'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# y=df['affordability_home_30yr_Payment_20_Perc_Down']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determining input dimensions\n",
    "len(columns_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the feature group\n",
    "X = df_train[columns_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.8307 - accuracy: 0.5132\n",
      "Epoch 2/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2466 - accuracy: 0.9398\n",
      "Epoch 3/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1470 - accuracy: 0.9398\n",
      "Epoch 4/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0987 - accuracy: 0.9530\n",
      "Epoch 5/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0717 - accuracy: 0.9831\n",
      "Epoch 6/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0540 - accuracy: 0.9868\n",
      "Epoch 7/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0437 - accuracy: 0.9868\n",
      "Epoch 8/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0379 - accuracy: 0.9868\n",
      "Epoch 9/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0317 - accuracy: 0.9868\n",
      "Epoch 10/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0288 - accuracy: 0.9868\n",
      "Epoch 11/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0265 - accuracy: 0.9887\n",
      "Epoch 12/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0246 - accuracy: 0.9868\n",
      "Epoch 13/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0252 - accuracy: 0.9887\n",
      "Epoch 14/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0226 - accuracy: 0.9887\n",
      "Epoch 15/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0225 - accuracy: 0.9868\n",
      "Epoch 16/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0219 - accuracy: 0.9868\n",
      "Epoch 17/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0218 - accuracy: 0.9906\n",
      "Epoch 18/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0234 - accuracy: 0.9868\n",
      "Epoch 19/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0231 - accuracy: 0.9887\n",
      "Epoch 20/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0197 - accuracy: 0.9887\n",
      "Epoch 21/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0199 - accuracy: 0.9887\n",
      "Epoch 22/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0196 - accuracy: 0.9906\n",
      "Epoch 23/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0194 - accuracy: 0.9906\n",
      "Epoch 24/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0187 - accuracy: 0.9887\n",
      "Epoch 25/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0200 - accuracy: 0.9906\n",
      "6/6 - 0s - loss: 0.0570 - accuracy: 0.9831 - 129ms/epoch - 21ms/step\n",
      "Loss: 0.05703488364815712, Accuracy: 0.983146071434021\n",
      "Epoch 1/25\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.5861 - accuracy: 0.7143\n",
      "Epoch 2/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.3803 - accuracy: 0.8985\n",
      "Epoch 3/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2478 - accuracy: 0.9286\n",
      "Epoch 4/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.1800 - accuracy: 0.9455\n",
      "Epoch 5/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.1508 - accuracy: 0.9417\n",
      "Epoch 6/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.1332 - accuracy: 0.9417\n",
      "Epoch 7/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.1237 - accuracy: 0.9474\n",
      "Epoch 8/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.1188 - accuracy: 0.9624\n",
      "Epoch 9/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1029 - accuracy: 0.9624\n",
      "Epoch 10/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0997 - accuracy: 0.9568\n",
      "Epoch 11/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0919 - accuracy: 0.9662\n",
      "Epoch 12/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0900 - accuracy: 0.9680\n",
      "Epoch 13/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0877 - accuracy: 0.9643\n",
      "Epoch 14/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0889 - accuracy: 0.9605\n",
      "Epoch 15/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0889 - accuracy: 0.9605\n",
      "Epoch 16/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0862 - accuracy: 0.9624\n",
      "Epoch 17/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0830 - accuracy: 0.9643\n",
      "Epoch 18/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0765 - accuracy: 0.9662\n",
      "Epoch 19/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0734 - accuracy: 0.9643\n",
      "Epoch 20/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0720 - accuracy: 0.9699\n",
      "Epoch 21/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0767 - accuracy: 0.9568\n",
      "Epoch 22/25\n",
      "17/17 [==============================] - 0s 904us/step - loss: 0.0678 - accuracy: 0.9718\n",
      "Epoch 23/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0683 - accuracy: 0.9699\n",
      "Epoch 24/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0629 - accuracy: 0.9793\n",
      "Epoch 25/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0698 - accuracy: 0.9624\n",
      "6/6 - 0s - loss: 0.2707 - accuracy: 0.9213 - 93ms/epoch - 15ms/step\n",
      "Loss: 0.2707493007183075, Accuracy: 0.9213483333587646\n",
      "Epoch 1/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.6584 - accuracy: 0.6410\n",
      "Epoch 2/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3484 - accuracy: 0.8929\n",
      "Epoch 3/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.2077 - accuracy: 0.9455\n",
      "Epoch 4/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.1337 - accuracy: 0.9643\n",
      "Epoch 5/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0999 - accuracy: 0.9718\n",
      "Epoch 6/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0833 - accuracy: 0.9718\n",
      "Epoch 7/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0790 - accuracy: 0.9680\n",
      "Epoch 8/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0658 - accuracy: 0.9756\n",
      "Epoch 9/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0602 - accuracy: 0.9774\n",
      "Epoch 10/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0591 - accuracy: 0.9793\n",
      "Epoch 11/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0552 - accuracy: 0.9793\n",
      "Epoch 12/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0529 - accuracy: 0.9756\n",
      "Epoch 13/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0531 - accuracy: 0.9737\n",
      "Epoch 14/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0483 - accuracy: 0.9793\n",
      "Epoch 15/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0481 - accuracy: 0.9774\n",
      "Epoch 16/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0503 - accuracy: 0.9793\n",
      "Epoch 17/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0507 - accuracy: 0.9737\n",
      "Epoch 18/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0483 - accuracy: 0.9737\n",
      "Epoch 19/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0445 - accuracy: 0.9831\n",
      "Epoch 20/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0482 - accuracy: 0.9756\n",
      "Epoch 21/25\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.0487 - accuracy: 0.9737\n",
      "Epoch 22/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0475 - accuracy: 0.9793\n",
      "Epoch 23/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0432 - accuracy: 0.9812\n",
      "Epoch 24/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0438 - accuracy: 0.9756\n",
      "Epoch 25/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0427 - accuracy: 0.9774\n",
      "6/6 - 0s - loss: 0.1548 - accuracy: 0.9551 - 91ms/epoch - 15ms/step\n",
      "Loss: 0.1548413783311844, Accuracy: 0.9550561904907227\n",
      "Epoch 1/25\n",
      "17/17 [==============================] - 0s 967us/step - loss: 0.3817 - accuracy: 0.8459\n",
      "Epoch 2/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.1493 - accuracy: 0.9511\n",
      "Epoch 3/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0709 - accuracy: 0.9850\n",
      "Epoch 4/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0452 - accuracy: 0.9887\n",
      "Epoch 5/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0393 - accuracy: 0.9868\n",
      "Epoch 6/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0333 - accuracy: 0.9887\n",
      "Epoch 7/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0336 - accuracy: 0.9887\n",
      "Epoch 8/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0328 - accuracy: 0.9850\n",
      "Epoch 9/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0292 - accuracy: 0.9850\n",
      "Epoch 10/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0300 - accuracy: 0.9868\n",
      "Epoch 11/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0269 - accuracy: 0.9906\n",
      "Epoch 12/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0264 - accuracy: 0.9887\n",
      "Epoch 13/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0274 - accuracy: 0.9887\n",
      "Epoch 14/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0254 - accuracy: 0.9887\n",
      "Epoch 15/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0267 - accuracy: 0.9868\n",
      "Epoch 16/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0269 - accuracy: 0.9906\n",
      "Epoch 17/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0246 - accuracy: 0.9887\n",
      "Epoch 18/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0234 - accuracy: 0.9868\n",
      "Epoch 19/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0248 - accuracy: 0.9887\n",
      "Epoch 20/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0243 - accuracy: 0.9887\n",
      "Epoch 21/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0232 - accuracy: 0.9887\n",
      "Epoch 22/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0216 - accuracy: 0.9887\n",
      "Epoch 23/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0207 - accuracy: 0.9906\n",
      "Epoch 24/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0229 - accuracy: 0.9906\n",
      "Epoch 25/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0217 - accuracy: 0.9868\n",
      "6/6 - 0s - loss: 0.0867 - accuracy: 0.9719 - 94ms/epoch - 16ms/step\n",
      "Loss: 0.08670499920845032, Accuracy: 0.9719101190567017\n",
      "Epoch 1/25\n",
      "17/17 [==============================] - 0s 904us/step - loss: 0.4491 - accuracy: 0.7876\n",
      "Epoch 2/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.1960 - accuracy: 0.9267\n",
      "Epoch 3/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0981 - accuracy: 0.9699\n",
      "Epoch 4/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0596 - accuracy: 0.9774\n",
      "Epoch 5/25\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.0478 - accuracy: 0.9793\n",
      "Epoch 6/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0429 - accuracy: 0.9793\n",
      "Epoch 7/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0385 - accuracy: 0.9812\n",
      "Epoch 8/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0367 - accuracy: 0.9831\n",
      "Epoch 9/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0388 - accuracy: 0.9793\n",
      "Epoch 10/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0382 - accuracy: 0.9737\n",
      "Epoch 11/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0359 - accuracy: 0.9868\n",
      "Epoch 12/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0363 - accuracy: 0.9793\n",
      "Epoch 13/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0325 - accuracy: 0.9812\n",
      "Epoch 14/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0358 - accuracy: 0.9812\n",
      "Epoch 15/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0317 - accuracy: 0.9831\n",
      "Epoch 16/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0355 - accuracy: 0.9812\n",
      "Epoch 17/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0317 - accuracy: 0.9831\n",
      "Epoch 18/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0294 - accuracy: 0.9850\n",
      "Epoch 19/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0319 - accuracy: 0.9812\n",
      "Epoch 20/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0315 - accuracy: 0.9812\n",
      "Epoch 21/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0337 - accuracy: 0.9831\n",
      "Epoch 22/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0304 - accuracy: 0.9850\n",
      "Epoch 23/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0296 - accuracy: 0.9850\n",
      "Epoch 24/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0293 - accuracy: 0.9868\n",
      "Epoch 25/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0328 - accuracy: 0.9774\n",
      "6/6 - 0s - loss: 0.0487 - accuracy: 0.9888 - 91ms/epoch - 15ms/step\n",
      "Loss: 0.0487048476934433, Accuracy: 0.9887640476226807\n",
      "Epoch 1/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.5627 - accuracy: 0.6823\n",
      "Epoch 2/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3099 - accuracy: 0.8496\n",
      "Epoch 3/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.1898 - accuracy: 0.9248\n",
      "Epoch 4/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.1224 - accuracy: 0.9643\n",
      "Epoch 5/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0863 - accuracy: 0.9699\n",
      "Epoch 6/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0731 - accuracy: 0.9643\n",
      "Epoch 7/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0653 - accuracy: 0.9680\n",
      "Epoch 8/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0608 - accuracy: 0.9699\n",
      "Epoch 9/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0558 - accuracy: 0.9756\n",
      "Epoch 10/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0570 - accuracy: 0.9699\n",
      "Epoch 11/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0592 - accuracy: 0.9699\n",
      "Epoch 12/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0588 - accuracy: 0.9718\n",
      "Epoch 13/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0565 - accuracy: 0.9699\n",
      "Epoch 14/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0521 - accuracy: 0.9718\n",
      "Epoch 15/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0533 - accuracy: 0.9774\n",
      "Epoch 16/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0516 - accuracy: 0.9680\n",
      "Epoch 17/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0483 - accuracy: 0.9793\n",
      "Epoch 18/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0491 - accuracy: 0.9718\n",
      "Epoch 19/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0489 - accuracy: 0.9756\n",
      "Epoch 20/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0497 - accuracy: 0.9756\n",
      "Epoch 21/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0528 - accuracy: 0.9680\n",
      "Epoch 22/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0484 - accuracy: 0.9718\n",
      "Epoch 23/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0479 - accuracy: 0.9793\n",
      "Epoch 24/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0500 - accuracy: 0.9662\n",
      "Epoch 25/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0478 - accuracy: 0.9737\n",
      "6/6 - 0s - loss: 0.2062 - accuracy: 0.9551 - 92ms/epoch - 15ms/step\n",
      "Loss: 0.20617446303367615, Accuracy: 0.9550561904907227\n",
      "Epoch 1/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.4725 - accuracy: 0.8214\n",
      "Epoch 2/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2878 - accuracy: 0.8571\n",
      "Epoch 3/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.1973 - accuracy: 0.9023\n",
      "Epoch 4/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.1324 - accuracy: 0.9436\n",
      "Epoch 5/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0920 - accuracy: 0.9793\n",
      "Epoch 6/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0692 - accuracy: 0.9812\n",
      "Epoch 7/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0611 - accuracy: 0.9756\n",
      "Epoch 8/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0539 - accuracy: 0.9737\n",
      "Epoch 9/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0539 - accuracy: 0.9737\n",
      "Epoch 10/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0487 - accuracy: 0.9756\n",
      "Epoch 11/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0481 - accuracy: 0.9774\n",
      "Epoch 12/25\n",
      "17/17 [==============================] - 0s 904us/step - loss: 0.0452 - accuracy: 0.9756\n",
      "Epoch 13/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0444 - accuracy: 0.9737\n",
      "Epoch 14/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0420 - accuracy: 0.9793\n",
      "Epoch 15/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0390 - accuracy: 0.9793\n",
      "Epoch 16/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0391 - accuracy: 0.9831\n",
      "Epoch 17/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0409 - accuracy: 0.9793\n",
      "Epoch 18/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0389 - accuracy: 0.9774\n",
      "Epoch 19/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0432 - accuracy: 0.9774\n",
      "Epoch 20/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0476 - accuracy: 0.9718\n",
      "Epoch 21/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0405 - accuracy: 0.9774\n",
      "Epoch 22/25\n",
      "17/17 [==============================] - 0s 904us/step - loss: 0.0349 - accuracy: 0.9812\n",
      "Epoch 23/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0396 - accuracy: 0.9756\n",
      "Epoch 24/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0454 - accuracy: 0.9793\n",
      "Epoch 25/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0491 - accuracy: 0.9774\n",
      "6/6 - 0s - loss: 0.1343 - accuracy: 0.9888 - 96ms/epoch - 16ms/step\n",
      "Loss: 0.13434696197509766, Accuracy: 0.9887640476226807\n",
      "Epoch 1/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.3299 - accuracy: 0.9060\n",
      "Epoch 2/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.1727 - accuracy: 0.9154\n",
      "Epoch 3/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.1039 - accuracy: 0.9549\n",
      "Epoch 4/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0717 - accuracy: 0.9643\n",
      "Epoch 5/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0507 - accuracy: 0.9756\n",
      "Epoch 6/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0454 - accuracy: 0.9793\n",
      "Epoch 7/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0414 - accuracy: 0.9812\n",
      "Epoch 8/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0383 - accuracy: 0.9831\n",
      "Epoch 9/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0374 - accuracy: 0.9831\n",
      "Epoch 10/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0360 - accuracy: 0.9887\n",
      "Epoch 11/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0353 - accuracy: 0.9850\n",
      "Epoch 12/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0347 - accuracy: 0.9906\n",
      "Epoch 13/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0321 - accuracy: 0.9850\n",
      "Epoch 14/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0301 - accuracy: 0.9887\n",
      "Epoch 15/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0294 - accuracy: 0.9906\n",
      "Epoch 16/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0281 - accuracy: 0.9925\n",
      "Epoch 17/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0295 - accuracy: 0.9887\n",
      "Epoch 18/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0250 - accuracy: 0.9944\n",
      "Epoch 19/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0254 - accuracy: 0.9887\n",
      "Epoch 20/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0238 - accuracy: 0.9925\n",
      "Epoch 21/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0232 - accuracy: 0.9906\n",
      "Epoch 22/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0236 - accuracy: 0.9850\n",
      "Epoch 23/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0292 - accuracy: 0.9850\n",
      "Epoch 24/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0218 - accuracy: 0.9925\n",
      "Epoch 25/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0211 - accuracy: 0.9944\n",
      "6/6 - 0s - loss: 0.0983 - accuracy: 0.9607 - 90ms/epoch - 15ms/step\n",
      "Loss: 0.09825616329908371, Accuracy: 0.9606741666793823\n",
      "Epoch 1/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.3664 - accuracy: 0.8947\n",
      "Epoch 2/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.1602 - accuracy: 0.9380\n",
      "Epoch 3/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0959 - accuracy: 0.9680\n",
      "Epoch 4/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0688 - accuracy: 0.9812\n",
      "Epoch 5/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0570 - accuracy: 0.9793\n",
      "Epoch 6/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0507 - accuracy: 0.9793\n",
      "Epoch 7/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0453 - accuracy: 0.9793\n",
      "Epoch 8/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0448 - accuracy: 0.9774\n",
      "Epoch 9/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0397 - accuracy: 0.9812\n",
      "Epoch 10/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0392 - accuracy: 0.9793\n",
      "Epoch 11/25\n",
      "17/17 [==============================] - 0s 904us/step - loss: 0.0438 - accuracy: 0.9812\n",
      "Epoch 12/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0345 - accuracy: 0.9850\n",
      "Epoch 13/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0365 - accuracy: 0.9812\n",
      "Epoch 14/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0338 - accuracy: 0.9850\n",
      "Epoch 15/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0333 - accuracy: 0.9868\n",
      "Epoch 16/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0315 - accuracy: 0.9868\n",
      "Epoch 17/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0321 - accuracy: 0.9868\n",
      "Epoch 18/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0298 - accuracy: 0.9887\n",
      "Epoch 19/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0314 - accuracy: 0.9850\n",
      "Epoch 20/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0325 - accuracy: 0.9850\n",
      "Epoch 21/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0277 - accuracy: 0.9906\n",
      "Epoch 22/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0269 - accuracy: 0.9906\n",
      "Epoch 23/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0274 - accuracy: 0.9906\n",
      "Epoch 24/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0264 - accuracy: 0.9906\n",
      "Epoch 25/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0299 - accuracy: 0.9868\n",
      "6/6 - 0s - loss: 0.0638 - accuracy: 0.9775 - 101ms/epoch - 17ms/step\n",
      "Loss: 0.06379713118076324, Accuracy: 0.9775280952453613\n",
      "Epoch 1/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.5572 - accuracy: 0.7143\n",
      "Epoch 2/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.3022 - accuracy: 0.8853\n",
      "Epoch 3/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.1401 - accuracy: 0.9756\n",
      "Epoch 4/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0581 - accuracy: 0.9868\n",
      "Epoch 5/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0339 - accuracy: 0.9925\n",
      "Epoch 6/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0260 - accuracy: 0.9944\n",
      "Epoch 7/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0213 - accuracy: 0.9944\n",
      "Epoch 8/25\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.0203 - accuracy: 0.9906\n",
      "Epoch 9/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0220 - accuracy: 0.9925\n",
      "Epoch 10/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0171 - accuracy: 0.9944\n",
      "Epoch 11/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0192 - accuracy: 0.9925\n",
      "Epoch 12/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0174 - accuracy: 0.9944\n",
      "Epoch 13/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0145 - accuracy: 0.9944\n",
      "Epoch 14/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0141 - accuracy: 0.9944\n",
      "Epoch 15/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0156 - accuracy: 0.9944\n",
      "Epoch 16/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0119 - accuracy: 0.9962\n",
      "Epoch 17/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0133 - accuracy: 0.9925\n",
      "Epoch 18/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0141 - accuracy: 0.9944\n",
      "Epoch 19/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0114 - accuracy: 0.9944\n",
      "Epoch 20/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0110 - accuracy: 0.9944\n",
      "Epoch 21/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0121 - accuracy: 0.9944\n",
      "Epoch 22/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0108 - accuracy: 0.9944\n",
      "Epoch 23/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0117 - accuracy: 0.9925\n",
      "Epoch 24/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0109 - accuracy: 0.9944\n",
      "Epoch 25/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0118 - accuracy: 0.9925\n",
      "6/6 - 0s - loss: 0.1539 - accuracy: 0.9775 - 96ms/epoch - 16ms/step\n",
      "Loss: 0.1539495289325714, Accuracy: 0.9775280952453613\n",
      "Epoch 1/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.5232 - accuracy: 0.7444\n",
      "Epoch 2/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.2808 - accuracy: 0.8872\n",
      "Epoch 3/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.1478 - accuracy: 0.9718\n",
      "Epoch 4/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0851 - accuracy: 0.9756\n",
      "Epoch 5/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0625 - accuracy: 0.9756\n",
      "Epoch 6/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0527 - accuracy: 0.9774\n",
      "Epoch 7/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0457 - accuracy: 0.9831\n",
      "Epoch 8/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0498 - accuracy: 0.9718\n",
      "Epoch 9/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0485 - accuracy: 0.9793\n",
      "Epoch 10/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0468 - accuracy: 0.9793\n",
      "Epoch 11/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0464 - accuracy: 0.9793\n",
      "Epoch 12/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0487 - accuracy: 0.9756\n",
      "Epoch 13/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0435 - accuracy: 0.9756\n",
      "Epoch 14/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0425 - accuracy: 0.9774\n",
      "Epoch 15/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0358 - accuracy: 0.9887\n",
      "Epoch 16/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0368 - accuracy: 0.9831\n",
      "Epoch 17/25\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.0377 - accuracy: 0.9812\n",
      "Epoch 18/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0341 - accuracy: 0.9850\n",
      "Epoch 19/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0377 - accuracy: 0.9812\n",
      "Epoch 20/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0340 - accuracy: 0.9831\n",
      "Epoch 21/25\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0334 - accuracy: 0.9831\n",
      "Epoch 22/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0354 - accuracy: 0.9850\n",
      "Epoch 23/25\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.0323 - accuracy: 0.9850\n",
      "Epoch 24/25\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.0389 - accuracy: 0.9812\n",
      "Epoch 25/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0419 - accuracy: 0.9774\n",
      "6/6 - 0s - loss: 0.1951 - accuracy: 0.9663 - 101ms/epoch - 17ms/step\n",
      "Loss: 0.19506673514842987, Accuracy: 0.966292142868042\n",
      "Epoch 1/25\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.5821 - accuracy: 0.6786\n",
      "Epoch 2/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2532 - accuracy: 0.8891\n",
      "Epoch 3/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.1488 - accuracy: 0.9455\n",
      "Epoch 4/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.1085 - accuracy: 0.9643\n",
      "Epoch 5/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0837 - accuracy: 0.9680\n",
      "Epoch 6/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0732 - accuracy: 0.9699\n",
      "Epoch 7/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0672 - accuracy: 0.9718\n",
      "Epoch 8/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0640 - accuracy: 0.9756\n",
      "Epoch 9/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0622 - accuracy: 0.9737\n",
      "Epoch 10/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0600 - accuracy: 0.9718\n",
      "Epoch 11/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0594 - accuracy: 0.9737\n",
      "Epoch 12/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0620 - accuracy: 0.9680\n",
      "Epoch 13/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0576 - accuracy: 0.9774\n",
      "Epoch 14/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0624 - accuracy: 0.9662\n",
      "Epoch 15/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0548 - accuracy: 0.9756\n",
      "Epoch 16/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0579 - accuracy: 0.9718\n",
      "Epoch 17/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0545 - accuracy: 0.9756\n",
      "Epoch 18/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0550 - accuracy: 0.9718\n",
      "Epoch 19/25\n",
      "17/17 [==============================] - 0s 904us/step - loss: 0.0553 - accuracy: 0.9756\n",
      "Epoch 20/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0530 - accuracy: 0.9737\n",
      "Epoch 21/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0505 - accuracy: 0.9756\n",
      "Epoch 22/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0517 - accuracy: 0.9774\n",
      "Epoch 23/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0521 - accuracy: 0.9737\n",
      "Epoch 24/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0530 - accuracy: 0.9737\n",
      "Epoch 25/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0522 - accuracy: 0.9737\n",
      "6/6 - 0s - loss: 0.1216 - accuracy: 0.9663 - 93ms/epoch - 15ms/step\n",
      "Loss: 0.121631920337677, Accuracy: 0.966292142868042\n",
      "Epoch 1/25\n",
      "17/17 [==============================] - 1s 997us/step - loss: 0.4474 - accuracy: 0.8158\n",
      "Epoch 2/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1931 - accuracy: 0.9154\n",
      "Epoch 3/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.1065 - accuracy: 0.9680\n",
      "Epoch 4/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0645 - accuracy: 0.9831\n",
      "Epoch 5/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0486 - accuracy: 0.9868\n",
      "Epoch 6/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0409 - accuracy: 0.9850\n",
      "Epoch 7/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0382 - accuracy: 0.9887\n",
      "Epoch 8/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0369 - accuracy: 0.9868\n",
      "Epoch 9/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0335 - accuracy: 0.9868\n",
      "Epoch 10/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0301 - accuracy: 0.9868\n",
      "Epoch 11/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0318 - accuracy: 0.9850\n",
      "Epoch 12/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0326 - accuracy: 0.9831\n",
      "Epoch 13/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0355 - accuracy: 0.9868\n",
      "Epoch 14/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0369 - accuracy: 0.9868\n",
      "Epoch 15/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0283 - accuracy: 0.9868\n",
      "Epoch 16/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0280 - accuracy: 0.9906\n",
      "Epoch 17/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0291 - accuracy: 0.9868\n",
      "Epoch 18/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0264 - accuracy: 0.9906\n",
      "Epoch 19/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0278 - accuracy: 0.9868\n",
      "Epoch 20/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0265 - accuracy: 0.9887\n",
      "Epoch 21/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0279 - accuracy: 0.9850\n",
      "Epoch 22/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0250 - accuracy: 0.9906\n",
      "Epoch 23/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0255 - accuracy: 0.9906\n",
      "Epoch 24/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0263 - accuracy: 0.9868\n",
      "Epoch 25/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0255 - accuracy: 0.9906\n",
      "6/6 - 0s - loss: 0.0873 - accuracy: 0.9719 - 93ms/epoch - 15ms/step\n",
      "Loss: 0.08728361129760742, Accuracy: 0.9719101190567017\n",
      "Epoch 1/25\n",
      "17/17 [==============================] - 0s 967us/step - loss: 0.5494 - accuracy: 0.7669\n",
      "Epoch 2/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3081 - accuracy: 0.9135\n",
      "Epoch 3/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.1746 - accuracy: 0.9586\n",
      "Epoch 4/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1155 - accuracy: 0.9624\n",
      "Epoch 5/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0894 - accuracy: 0.9737\n",
      "Epoch 6/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0801 - accuracy: 0.9737\n",
      "Epoch 7/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0777 - accuracy: 0.9718\n",
      "Epoch 8/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0685 - accuracy: 0.9718\n",
      "Epoch 9/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0701 - accuracy: 0.9774\n",
      "Epoch 10/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0684 - accuracy: 0.9699\n",
      "Epoch 11/25\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.0586 - accuracy: 0.9756\n",
      "Epoch 12/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0580 - accuracy: 0.9756\n",
      "Epoch 13/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0583 - accuracy: 0.9756\n",
      "Epoch 14/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0576 - accuracy: 0.9774\n",
      "Epoch 15/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0584 - accuracy: 0.9756\n",
      "Epoch 16/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0592 - accuracy: 0.9774\n",
      "Epoch 17/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0620 - accuracy: 0.9756\n",
      "Epoch 18/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0577 - accuracy: 0.9774\n",
      "Epoch 19/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0549 - accuracy: 0.9737\n",
      "Epoch 20/25\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0540 - accuracy: 0.9793\n",
      "Epoch 21/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0476 - accuracy: 0.9793\n",
      "Epoch 22/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0500 - accuracy: 0.9774\n",
      "Epoch 23/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0481 - accuracy: 0.9774\n",
      "Epoch 24/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0527 - accuracy: 0.9718\n",
      "Epoch 25/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0515 - accuracy: 0.9812\n",
      "6/6 - 0s - loss: 0.2788 - accuracy: 0.9382 - 92ms/epoch - 15ms/step\n",
      "Loss: 0.27876704931259155, Accuracy: 0.9382022619247437\n",
      "Epoch 1/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.5411 - accuracy: 0.7011\n",
      "Epoch 2/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.2888 - accuracy: 0.9060\n",
      "Epoch 3/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.1481 - accuracy: 0.9605\n",
      "Epoch 4/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0882 - accuracy: 0.9699\n",
      "Epoch 5/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0686 - accuracy: 0.9756\n",
      "Epoch 6/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0585 - accuracy: 0.9850\n",
      "Epoch 7/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0566 - accuracy: 0.9831\n",
      "Epoch 8/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0508 - accuracy: 0.9831\n",
      "Epoch 9/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0461 - accuracy: 0.9812\n",
      "Epoch 10/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0474 - accuracy: 0.9850\n",
      "Epoch 11/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0469 - accuracy: 0.9850\n",
      "Epoch 12/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0454 - accuracy: 0.9793\n",
      "Epoch 13/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0518 - accuracy: 0.9774\n",
      "Epoch 14/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0501 - accuracy: 0.9756\n",
      "Epoch 15/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0455 - accuracy: 0.9812\n",
      "Epoch 16/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0443 - accuracy: 0.9812\n",
      "Epoch 17/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0375 - accuracy: 0.9831\n",
      "Epoch 18/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0385 - accuracy: 0.9850\n",
      "Epoch 19/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0377 - accuracy: 0.9850\n",
      "Epoch 20/25\n",
      "17/17 [==============================] - 0s 967us/step - loss: 0.0369 - accuracy: 0.9850\n",
      "Epoch 21/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0399 - accuracy: 0.9850\n",
      "Epoch 22/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0403 - accuracy: 0.9812\n",
      "Epoch 23/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0374 - accuracy: 0.9868\n",
      "Epoch 24/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0361 - accuracy: 0.9850\n",
      "Epoch 25/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0374 - accuracy: 0.9831\n",
      "6/6 - 0s - loss: 0.0960 - accuracy: 0.9831 - 94ms/epoch - 16ms/step\n",
      "Loss: 0.0960315391421318, Accuracy: 0.983146071434021\n",
      "Epoch 1/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.4662 - accuracy: 0.7876\n",
      "Epoch 2/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2017 - accuracy: 0.9380\n",
      "Epoch 3/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0956 - accuracy: 0.9850\n",
      "Epoch 4/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0523 - accuracy: 0.9868\n",
      "Epoch 5/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0364 - accuracy: 0.9906\n",
      "Epoch 6/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0311 - accuracy: 0.9906\n",
      "Epoch 7/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0287 - accuracy: 0.9887\n",
      "Epoch 8/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0287 - accuracy: 0.9868\n",
      "Epoch 9/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0249 - accuracy: 0.9887\n",
      "Epoch 10/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0235 - accuracy: 0.9887\n",
      "Epoch 11/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0245 - accuracy: 0.9925\n",
      "Epoch 12/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0228 - accuracy: 0.9887\n",
      "Epoch 13/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0242 - accuracy: 0.9868\n",
      "Epoch 14/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0219 - accuracy: 0.9906\n",
      "Epoch 15/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0221 - accuracy: 0.9887\n",
      "Epoch 16/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0226 - accuracy: 0.9850\n",
      "Epoch 17/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0315 - accuracy: 0.9850\n",
      "Epoch 18/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0237 - accuracy: 0.9887\n",
      "Epoch 19/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0242 - accuracy: 0.9887\n",
      "Epoch 20/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0204 - accuracy: 0.9906\n",
      "Epoch 21/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0189 - accuracy: 0.9925\n",
      "Epoch 22/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0178 - accuracy: 0.9944\n",
      "Epoch 23/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0181 - accuracy: 0.9906\n",
      "Epoch 24/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0168 - accuracy: 0.9925\n",
      "Epoch 25/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0197 - accuracy: 0.9868\n",
      "6/6 - 0s - loss: 0.1033 - accuracy: 0.9775 - 93ms/epoch - 16ms/step\n",
      "Loss: 0.10330965369939804, Accuracy: 0.9775280952453613\n",
      "Epoch 1/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.4905 - accuracy: 0.8233\n",
      "Epoch 2/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.2085 - accuracy: 0.9211\n",
      "Epoch 3/25\n",
      "17/17 [==============================] - 0s 904us/step - loss: 0.0953 - accuracy: 0.9680\n",
      "Epoch 4/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0512 - accuracy: 0.9850\n",
      "Epoch 5/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0367 - accuracy: 0.9868\n",
      "Epoch 6/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0311 - accuracy: 0.9868\n",
      "Epoch 7/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0274 - accuracy: 0.9868\n",
      "Epoch 8/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0329 - accuracy: 0.9831\n",
      "Epoch 9/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0337 - accuracy: 0.9812\n",
      "Epoch 10/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0258 - accuracy: 0.9868\n",
      "Epoch 11/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0249 - accuracy: 0.9887\n",
      "Epoch 12/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0238 - accuracy: 0.9868\n",
      "Epoch 13/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0247 - accuracy: 0.9868\n",
      "Epoch 14/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0226 - accuracy: 0.9887\n",
      "Epoch 15/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0260 - accuracy: 0.9831\n",
      "Epoch 16/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0272 - accuracy: 0.9850\n",
      "Epoch 17/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0214 - accuracy: 0.9887\n",
      "Epoch 18/25\n",
      "17/17 [==============================] - 0s 967us/step - loss: 0.0237 - accuracy: 0.9868\n",
      "Epoch 19/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0231 - accuracy: 0.9868\n",
      "Epoch 20/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0236 - accuracy: 0.9812\n",
      "Epoch 21/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0237 - accuracy: 0.9887\n",
      "Epoch 22/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0211 - accuracy: 0.9868\n",
      "Epoch 23/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0214 - accuracy: 0.9887\n",
      "Epoch 24/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0208 - accuracy: 0.9887\n",
      "Epoch 25/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0227 - accuracy: 0.9868\n",
      "6/6 - 0s - loss: 0.1135 - accuracy: 0.9719 - 93ms/epoch - 15ms/step\n",
      "Loss: 0.1135176420211792, Accuracy: 0.9719101190567017\n",
      "Epoch 1/25\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.4400 - accuracy: 0.8308\n",
      "Epoch 2/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2970 - accuracy: 0.8383\n",
      "Epoch 3/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.2265 - accuracy: 0.8966\n",
      "Epoch 4/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.1749 - accuracy: 0.9361\n",
      "Epoch 5/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.1406 - accuracy: 0.9455\n",
      "Epoch 6/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1160 - accuracy: 0.9492\n",
      "Epoch 7/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.1020 - accuracy: 0.9549\n",
      "Epoch 8/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0928 - accuracy: 0.9586\n",
      "Epoch 9/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0875 - accuracy: 0.9662\n",
      "Epoch 10/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0808 - accuracy: 0.9624\n",
      "Epoch 11/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0866 - accuracy: 0.9511\n",
      "Epoch 12/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0788 - accuracy: 0.9605\n",
      "Epoch 13/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0735 - accuracy: 0.9586\n",
      "Epoch 14/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0791 - accuracy: 0.9624\n",
      "Epoch 15/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0738 - accuracy: 0.9662\n",
      "Epoch 16/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0707 - accuracy: 0.9680\n",
      "Epoch 17/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0692 - accuracy: 0.9605\n",
      "Epoch 18/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0697 - accuracy: 0.9680\n",
      "Epoch 19/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0638 - accuracy: 0.9756\n",
      "Epoch 20/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0662 - accuracy: 0.9680\n",
      "Epoch 21/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0645 - accuracy: 0.9680\n",
      "Epoch 22/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0716 - accuracy: 0.9662\n",
      "Epoch 23/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0660 - accuracy: 0.9662\n",
      "Epoch 24/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0668 - accuracy: 0.9662\n",
      "Epoch 25/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0577 - accuracy: 0.9699\n",
      "6/6 - 0s - loss: 0.2769 - accuracy: 0.9551 - 94ms/epoch - 16ms/step\n",
      "Loss: 0.2769151031970978, Accuracy: 0.9550561904907227\n",
      "Epoch 1/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.5910 - accuracy: 0.6729\n",
      "Epoch 2/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3924 - accuracy: 0.8252\n",
      "Epoch 3/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.2703 - accuracy: 0.9173\n",
      "Epoch 4/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.1964 - accuracy: 0.9380\n",
      "Epoch 5/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1602 - accuracy: 0.9455\n",
      "Epoch 6/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.1389 - accuracy: 0.9455\n",
      "Epoch 7/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1287 - accuracy: 0.9530\n",
      "Epoch 8/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1259 - accuracy: 0.9474\n",
      "Epoch 9/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1223 - accuracy: 0.9417\n",
      "Epoch 10/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1191 - accuracy: 0.9492\n",
      "Epoch 11/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1086 - accuracy: 0.9568\n",
      "Epoch 12/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1130 - accuracy: 0.9549\n",
      "Epoch 13/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1043 - accuracy: 0.9530\n",
      "Epoch 14/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1023 - accuracy: 0.9624\n",
      "Epoch 15/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1006 - accuracy: 0.9586\n",
      "Epoch 16/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1000 - accuracy: 0.9586\n",
      "Epoch 17/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0998 - accuracy: 0.9586\n",
      "Epoch 18/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0972 - accuracy: 0.9568\n",
      "Epoch 19/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0937 - accuracy: 0.9624\n",
      "Epoch 20/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0918 - accuracy: 0.9586\n",
      "Epoch 21/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0901 - accuracy: 0.9586\n",
      "Epoch 22/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0923 - accuracy: 0.9624\n",
      "Epoch 23/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0838 - accuracy: 0.9624\n",
      "Epoch 24/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0854 - accuracy: 0.9662\n",
      "Epoch 25/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0850 - accuracy: 0.9624\n",
      "6/6 - 0s - loss: 0.1954 - accuracy: 0.9382 - 93ms/epoch - 15ms/step\n",
      "Loss: 0.19540731608867645, Accuracy: 0.9382022619247437\n",
      "Epoch 1/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.5414 - accuracy: 0.7594\n",
      "Epoch 2/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.3077 - accuracy: 0.8966\n",
      "Epoch 3/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.1886 - accuracy: 0.9380\n",
      "Epoch 4/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.1379 - accuracy: 0.9530\n",
      "Epoch 5/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1205 - accuracy: 0.9568\n",
      "Epoch 6/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1124 - accuracy: 0.9605\n",
      "Epoch 7/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.1095 - accuracy: 0.9568\n",
      "Epoch 8/25\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.1066 - accuracy: 0.9549\n",
      "Epoch 9/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1070 - accuracy: 0.9605\n",
      "Epoch 10/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1063 - accuracy: 0.9530\n",
      "Epoch 11/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0977 - accuracy: 0.9624\n",
      "Epoch 12/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1039 - accuracy: 0.9492\n",
      "Epoch 13/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0938 - accuracy: 0.9624\n",
      "Epoch 14/25\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0958 - accuracy: 0.9568\n",
      "Epoch 15/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0964 - accuracy: 0.9624\n",
      "Epoch 16/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0964 - accuracy: 0.9586\n",
      "Epoch 17/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0900 - accuracy: 0.9643\n",
      "Epoch 18/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0911 - accuracy: 0.9586\n",
      "Epoch 19/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0882 - accuracy: 0.9605\n",
      "Epoch 20/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0874 - accuracy: 0.9643\n",
      "Epoch 21/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0901 - accuracy: 0.9605\n",
      "Epoch 22/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0861 - accuracy: 0.9624\n",
      "Epoch 23/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0842 - accuracy: 0.9662\n",
      "Epoch 24/25\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0840 - accuracy: 0.9624\n",
      "Epoch 25/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0842 - accuracy: 0.9643\n",
      "6/6 - 0s - loss: 0.1830 - accuracy: 0.9494 - 90ms/epoch - 15ms/step\n",
      "Loss: 0.18295808136463165, Accuracy: 0.949438214302063\n",
      "Epoch 1/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.5893 - accuracy: 0.6786\n",
      "Epoch 2/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.2827 - accuracy: 0.9079\n",
      "Epoch 3/25\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.1540 - accuracy: 0.9568\n",
      "Epoch 4/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0917 - accuracy: 0.9756\n",
      "Epoch 5/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0670 - accuracy: 0.9793\n",
      "Epoch 6/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0559 - accuracy: 0.9737\n",
      "Epoch 7/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0550 - accuracy: 0.9774\n",
      "Epoch 8/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0495 - accuracy: 0.9774\n",
      "Epoch 9/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0512 - accuracy: 0.9774\n",
      "Epoch 10/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0456 - accuracy: 0.9756\n",
      "Epoch 11/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0513 - accuracy: 0.9774\n",
      "Epoch 12/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0464 - accuracy: 0.9774\n",
      "Epoch 13/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0497 - accuracy: 0.9756\n",
      "Epoch 14/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0491 - accuracy: 0.9756\n",
      "Epoch 15/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0468 - accuracy: 0.9737\n",
      "Epoch 16/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0427 - accuracy: 0.9793\n",
      "Epoch 17/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0464 - accuracy: 0.9737\n",
      "Epoch 18/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0471 - accuracy: 0.9774\n",
      "Epoch 19/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0437 - accuracy: 0.9793\n",
      "Epoch 20/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0422 - accuracy: 0.9812\n",
      "Epoch 21/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0429 - accuracy: 0.9812\n",
      "Epoch 22/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0443 - accuracy: 0.9793\n",
      "Epoch 23/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0419 - accuracy: 0.9812\n",
      "Epoch 24/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0434 - accuracy: 0.9774\n",
      "Epoch 25/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0419 - accuracy: 0.9774\n",
      "6/6 - 0s - loss: 0.1400 - accuracy: 0.9663 - 98ms/epoch - 16ms/step\n",
      "Loss: 0.1400124579668045, Accuracy: 0.966292142868042\n",
      "Epoch 1/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.4199 - accuracy: 0.8647\n",
      "Epoch 2/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1499 - accuracy: 0.9605\n",
      "Epoch 3/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0857 - accuracy: 0.9643\n",
      "Epoch 4/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0506 - accuracy: 0.9756\n",
      "Epoch 5/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0310 - accuracy: 0.9868\n",
      "Epoch 6/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0171 - accuracy: 0.9981\n",
      "Epoch 7/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 8/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 9/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 10/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 11/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 12/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 13/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 8.9822e-04 - accuracy: 1.0000\n",
      "Epoch 14/25\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 7.0836e-04 - accuracy: 1.0000\n",
      "Epoch 15/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 5.7766e-04 - accuracy: 1.0000\n",
      "Epoch 16/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 4.7487e-04 - accuracy: 1.0000\n",
      "Epoch 17/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 3.9235e-04 - accuracy: 1.0000\n",
      "Epoch 18/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 3.3277e-04 - accuracy: 1.0000\n",
      "Epoch 19/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 2.9066e-04 - accuracy: 1.0000\n",
      "Epoch 20/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 2.5087e-04 - accuracy: 1.0000\n",
      "Epoch 21/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 2.2124e-04 - accuracy: 1.0000\n",
      "Epoch 22/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 1.9567e-04 - accuracy: 1.0000\n",
      "Epoch 23/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 1.7579e-04 - accuracy: 1.0000\n",
      "Epoch 24/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 1.5765e-04 - accuracy: 1.0000\n",
      "Epoch 25/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 1.4283e-04 - accuracy: 1.0000\n",
      "6/6 - 0s - loss: 0.1494 - accuracy: 0.9888 - 98ms/epoch - 16ms/step\n",
      "Loss: 0.14941121637821198, Accuracy: 0.9887640476226807\n",
      "Epoch 1/25\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.3601 - accuracy: 0.8722\n",
      "Epoch 2/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1565 - accuracy: 0.9455\n",
      "Epoch 3/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.1071 - accuracy: 0.9455\n",
      "Epoch 4/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0828 - accuracy: 0.9586\n",
      "Epoch 5/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0655 - accuracy: 0.9793\n",
      "Epoch 6/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0500 - accuracy: 0.9850\n",
      "Epoch 7/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0383 - accuracy: 0.9850\n",
      "Epoch 8/25\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.0332 - accuracy: 0.9850\n",
      "Epoch 9/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0297 - accuracy: 0.9887\n",
      "Epoch 10/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0252 - accuracy: 0.9906\n",
      "Epoch 11/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0241 - accuracy: 0.9925\n",
      "Epoch 12/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0219 - accuracy: 0.9944\n",
      "Epoch 13/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0212 - accuracy: 0.9906\n",
      "Epoch 14/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0197 - accuracy: 0.9925\n",
      "Epoch 15/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0178 - accuracy: 0.9925\n",
      "Epoch 16/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0169 - accuracy: 0.9925\n",
      "Epoch 17/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0165 - accuracy: 0.9925\n",
      "Epoch 18/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0165 - accuracy: 0.9925\n",
      "Epoch 19/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0157 - accuracy: 0.9925\n",
      "Epoch 20/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0165 - accuracy: 0.9925\n",
      "Epoch 21/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0160 - accuracy: 0.9944\n",
      "Epoch 22/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.0145 - accuracy: 0.9944\n",
      "Epoch 23/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.0166 - accuracy: 0.9887\n",
      "Epoch 24/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0138 - accuracy: 0.9925\n",
      "Epoch 25/25\n",
      "17/17 [==============================] - 0s 904us/step - loss: 0.0133 - accuracy: 0.9944\n",
      "6/6 - 0s - loss: 0.0420 - accuracy: 0.9719 - 92ms/epoch - 15ms/step\n",
      "Loss: 0.04202089458703995, Accuracy: 0.9719101190567017\n",
      "Epoch 1/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.5885 - accuracy: 0.6711\n",
      "Epoch 2/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.3967 - accuracy: 0.8045\n",
      "Epoch 3/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.2951 - accuracy: 0.8947\n",
      "Epoch 4/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.2291 - accuracy: 0.9248\n",
      "Epoch 5/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1908 - accuracy: 0.9267\n",
      "Epoch 6/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.1722 - accuracy: 0.9192\n",
      "Epoch 7/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1645 - accuracy: 0.9267\n",
      "Epoch 8/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.1579 - accuracy: 0.9286\n",
      "Epoch 9/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.1516 - accuracy: 0.9323\n",
      "Epoch 10/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1485 - accuracy: 0.9342\n",
      "Epoch 11/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1475 - accuracy: 0.9342\n",
      "Epoch 12/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.1393 - accuracy: 0.9323\n",
      "Epoch 13/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1428 - accuracy: 0.9361\n",
      "Epoch 14/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1360 - accuracy: 0.9398\n",
      "Epoch 15/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.1324 - accuracy: 0.9323\n",
      "Epoch 16/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.1368 - accuracy: 0.9417\n",
      "Epoch 17/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1339 - accuracy: 0.9361\n",
      "Epoch 18/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.1329 - accuracy: 0.9417\n",
      "Epoch 19/25\n",
      "17/17 [==============================] - 0s 967us/step - loss: 0.1267 - accuracy: 0.9455\n",
      "Epoch 20/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1216 - accuracy: 0.9436\n",
      "Epoch 21/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.1343 - accuracy: 0.9248\n",
      "Epoch 22/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1314 - accuracy: 0.9361\n",
      "Epoch 23/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.1225 - accuracy: 0.9436\n",
      "Epoch 24/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.1151 - accuracy: 0.9492\n",
      "Epoch 25/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1181 - accuracy: 0.9436\n",
      "6/6 - 0s - loss: 0.3613 - accuracy: 0.8989 - 103ms/epoch - 17ms/step\n",
      "Loss: 0.36126813292503357, Accuracy: 0.898876428604126\n",
      "Epoch 1/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.5790 - accuracy: 0.7143\n",
      "Epoch 2/25\n",
      "17/17 [==============================] - 0s 967us/step - loss: 0.3356 - accuracy: 0.8891\n",
      "Epoch 3/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.2282 - accuracy: 0.9211\n",
      "Epoch 4/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1853 - accuracy: 0.9248\n",
      "Epoch 5/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.1669 - accuracy: 0.9323\n",
      "Epoch 6/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1578 - accuracy: 0.9361\n",
      "Epoch 7/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1516 - accuracy: 0.9380\n",
      "Epoch 8/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1531 - accuracy: 0.9361\n",
      "Epoch 9/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1410 - accuracy: 0.9361\n",
      "Epoch 10/25\n",
      "17/17 [==============================] - 0s 873us/step - loss: 0.1404 - accuracy: 0.9398\n",
      "Epoch 11/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.1404 - accuracy: 0.9417\n",
      "Epoch 12/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1360 - accuracy: 0.9398\n",
      "Epoch 13/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1344 - accuracy: 0.9398\n",
      "Epoch 14/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1351 - accuracy: 0.9436\n",
      "Epoch 15/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.1361 - accuracy: 0.9455\n",
      "Epoch 16/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.1259 - accuracy: 0.9455\n",
      "Epoch 17/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.1293 - accuracy: 0.9380\n",
      "Epoch 18/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1331 - accuracy: 0.9380\n",
      "Epoch 19/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.1251 - accuracy: 0.9436\n",
      "Epoch 20/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1205 - accuracy: 0.9436\n",
      "Epoch 21/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1209 - accuracy: 0.9436\n",
      "Epoch 22/25\n",
      "17/17 [==============================] - 0s 997us/step - loss: 0.1200 - accuracy: 0.9455\n",
      "Epoch 23/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1240 - accuracy: 0.9436\n",
      "Epoch 24/25\n",
      "17/17 [==============================] - 0s 935us/step - loss: 0.1277 - accuracy: 0.9417\n",
      "Epoch 25/25\n",
      "17/17 [==============================] - 0s 1ms/step - loss: 0.1260 - accuracy: 0.9342\n",
      "6/6 - 0s - loss: 0.2761 - accuracy: 0.9270 - 95ms/epoch - 16ms/step\n",
      "Loss: 0.2760906517505646, Accuracy: 0.9269663095474243\n"
     ]
    }
   ],
   "source": [
    "# Testing the features in a test, train split group\n",
    "\n",
    "for target in target_list:\n",
    "    y=df_train[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    nn_model = tf.keras.models.Sequential()\n",
    "    nn_model.add(tf.keras.layers.Dense(units=100, activation=\"relu\", input_dim=84))\n",
    "    nn_model.add(tf.keras.layers.Dense(units=50, activation=\"relu\"))\n",
    "    nn_model.add(tf.keras.layers.Dense(units=25, activation=\"relu\"))\n",
    "    nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "    # Compile the Sequential model together and customize metrics\n",
    "    nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "    # Train the model\n",
    "    fit_model = nn_model.fit(X_train_scaled, y_train, epochs=25)\n",
    "\n",
    "    # Evaluate the model using the test data\n",
    "    model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "    print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Model from 2011-2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data from 2011 to 2020\n",
    "\n",
    "scaler = StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 0.3199 - accuracy: 0.9366\n",
      "Epoch 2/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1176 - accuracy: 0.9507\n",
      "Epoch 3/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0621 - accuracy: 0.9831\n",
      "Epoch 4/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0421 - accuracy: 0.9859\n",
      "Epoch 5/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0319 - accuracy: 0.9859\n",
      "Epoch 6/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0302 - accuracy: 0.9859\n",
      "Epoch 7/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0285 - accuracy: 0.9873\n",
      "Epoch 8/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0277 - accuracy: 0.9873\n",
      "Epoch 9/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0250 - accuracy: 0.9873\n",
      "Epoch 10/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0265 - accuracy: 0.9873\n",
      "Epoch 11/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0330 - accuracy: 0.9817\n",
      "Epoch 12/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0233 - accuracy: 0.9859\n",
      "Epoch 13/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0248 - accuracy: 0.9873\n",
      "Epoch 14/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0253 - accuracy: 0.9859\n",
      "Epoch 15/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0258 - accuracy: 0.9859\n",
      "Epoch 16/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0226 - accuracy: 0.9887\n",
      "Epoch 17/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0222 - accuracy: 0.9887\n",
      "Epoch 18/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0230 - accuracy: 0.9873\n",
      "Epoch 19/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0213 - accuracy: 0.9901\n",
      "Epoch 20/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0229 - accuracy: 0.9887\n",
      "Epoch 21/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0209 - accuracy: 0.9873\n",
      "Epoch 22/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0220 - accuracy: 0.9859\n",
      "Epoch 23/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0219 - accuracy: 0.9887\n",
      "Epoch 24/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0200 - accuracy: 0.9901\n",
      "Epoch 25/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0232 - accuracy: 0.9859\n",
      "23/23 - 0s - loss: 0.0211 - accuracy: 0.9873 - 106ms/epoch - 5ms/step\n",
      "Loss: 0.02114972472190857, Accuracy: 0.9873239398002625\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_100 (Dense)           (None, 100)               8500      \n",
      "                                                                 \n",
      " dense_101 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_102 (Dense)           (None, 25)                1275      \n",
      "                                                                 \n",
      " dense_103 (Dense)           (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,851\n",
      "Trainable params: 14,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.5368 - accuracy: 0.7592\n",
      "Epoch 2/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2837 - accuracy: 0.9070\n",
      "Epoch 3/25\n",
      "23/23 [==============================] - 0s 930us/step - loss: 0.1887 - accuracy: 0.9254\n",
      "Epoch 4/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1503 - accuracy: 0.9437\n",
      "Epoch 5/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.1325 - accuracy: 0.9521\n",
      "Epoch 6/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1237 - accuracy: 0.9549\n",
      "Epoch 7/25\n",
      "23/23 [==============================] - 0s 975us/step - loss: 0.1185 - accuracy: 0.9521\n",
      "Epoch 8/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.1148 - accuracy: 0.9507\n",
      "Epoch 9/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.1285 - accuracy: 0.9479\n",
      "Epoch 10/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1080 - accuracy: 0.9549\n",
      "Epoch 11/25\n",
      "23/23 [==============================] - 0s 930us/step - loss: 0.1106 - accuracy: 0.9507\n",
      "Epoch 12/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.1072 - accuracy: 0.9549\n",
      "Epoch 13/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1058 - accuracy: 0.9535\n",
      "Epoch 14/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.1000 - accuracy: 0.9592\n",
      "Epoch 15/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0981 - accuracy: 0.9563\n",
      "Epoch 16/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.1072 - accuracy: 0.9577\n",
      "Epoch 17/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0970 - accuracy: 0.9549\n",
      "Epoch 18/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0940 - accuracy: 0.9563\n",
      "Epoch 19/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0882 - accuracy: 0.9648\n",
      "Epoch 20/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0845 - accuracy: 0.9662\n",
      "Epoch 21/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0815 - accuracy: 0.9634\n",
      "Epoch 22/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0879 - accuracy: 0.9577\n",
      "Epoch 23/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0804 - accuracy: 0.9648\n",
      "Epoch 24/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0752 - accuracy: 0.9662\n",
      "Epoch 25/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0733 - accuracy: 0.9732\n",
      "23/23 - 0s - loss: 0.0660 - accuracy: 0.9732 - 103ms/epoch - 4ms/step\n",
      "Loss: 0.06599202007055283, Accuracy: 0.9732394218444824\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_104 (Dense)           (None, 100)               8500      \n",
      "                                                                 \n",
      " dense_105 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_106 (Dense)           (None, 25)                1275      \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,851\n",
      "Trainable params: 14,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.4681 - accuracy: 0.8155\n",
      "Epoch 2/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2013 - accuracy: 0.9380\n",
      "Epoch 3/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1149 - accuracy: 0.9592\n",
      "Epoch 4/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0809 - accuracy: 0.9732\n",
      "Epoch 5/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0806 - accuracy: 0.9718\n",
      "Epoch 6/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0706 - accuracy: 0.9662\n",
      "Epoch 7/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0640 - accuracy: 0.9732\n",
      "Epoch 8/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0619 - accuracy: 0.9690\n",
      "Epoch 9/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0672 - accuracy: 0.9690\n",
      "Epoch 10/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0577 - accuracy: 0.9746\n",
      "Epoch 11/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0527 - accuracy: 0.9746\n",
      "Epoch 12/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0549 - accuracy: 0.9704\n",
      "Epoch 13/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0522 - accuracy: 0.9718\n",
      "Epoch 14/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0535 - accuracy: 0.9803\n",
      "Epoch 15/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0541 - accuracy: 0.9775\n",
      "Epoch 16/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0593 - accuracy: 0.9746\n",
      "Epoch 17/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0522 - accuracy: 0.9690\n",
      "Epoch 18/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0521 - accuracy: 0.9746\n",
      "Epoch 19/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0517 - accuracy: 0.9746\n",
      "Epoch 20/25\n",
      "23/23 [==============================] - 0s 975us/step - loss: 0.0565 - accuracy: 0.9761\n",
      "Epoch 21/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0551 - accuracy: 0.9789\n",
      "Epoch 22/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0518 - accuracy: 0.9732\n",
      "Epoch 23/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0482 - accuracy: 0.9746\n",
      "Epoch 24/25\n",
      "23/23 [==============================] - 0s 975us/step - loss: 0.0458 - accuracy: 0.9775\n",
      "Epoch 25/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0452 - accuracy: 0.9732\n",
      "23/23 - 0s - loss: 0.0417 - accuracy: 0.9789 - 99ms/epoch - 4ms/step\n",
      "Loss: 0.041669752448797226, Accuracy: 0.9788732528686523\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_108 (Dense)           (None, 100)               8500      \n",
      "                                                                 \n",
      " dense_109 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_110 (Dense)           (None, 25)                1275      \n",
      "                                                                 \n",
      " dense_111 (Dense)           (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,851\n",
      "Trainable params: 14,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.5104 - accuracy: 0.7648\n",
      "Epoch 2/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.1645 - accuracy: 0.9535\n",
      "Epoch 3/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0721 - accuracy: 0.9803\n",
      "Epoch 4/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0486 - accuracy: 0.9845\n",
      "Epoch 5/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0398 - accuracy: 0.9873\n",
      "Epoch 6/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0394 - accuracy: 0.9845\n",
      "Epoch 7/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0375 - accuracy: 0.9817\n",
      "Epoch 8/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0358 - accuracy: 0.9859\n",
      "Epoch 9/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0338 - accuracy: 0.9873\n",
      "Epoch 10/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0355 - accuracy: 0.9859\n",
      "Epoch 11/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0340 - accuracy: 0.9887\n",
      "Epoch 12/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0322 - accuracy: 0.9845\n",
      "Epoch 13/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0303 - accuracy: 0.9873\n",
      "Epoch 14/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0326 - accuracy: 0.9859\n",
      "Epoch 15/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0355 - accuracy: 0.9831\n",
      "Epoch 16/25\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.0343 - accuracy: 0.9845\n",
      "Epoch 17/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0315 - accuracy: 0.9859\n",
      "Epoch 18/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0299 - accuracy: 0.9859\n",
      "Epoch 19/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0289 - accuracy: 0.9845\n",
      "Epoch 20/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0284 - accuracy: 0.9873\n",
      "Epoch 21/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0294 - accuracy: 0.9859\n",
      "Epoch 22/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0285 - accuracy: 0.9901\n",
      "Epoch 23/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0296 - accuracy: 0.9887\n",
      "Epoch 24/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0303 - accuracy: 0.9873\n",
      "Epoch 25/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0310 - accuracy: 0.9845\n",
      "23/23 - 0s - loss: 0.0252 - accuracy: 0.9887 - 100ms/epoch - 4ms/step\n",
      "Loss: 0.0252357330173254, Accuracy: 0.9887323975563049\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_112 (Dense)           (None, 100)               8500      \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_114 (Dense)           (None, 25)                1275      \n",
      "                                                                 \n",
      " dense_115 (Dense)           (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,851\n",
      "Trainable params: 14,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.4347 - accuracy: 0.8169\n",
      "Epoch 2/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.1564 - accuracy: 0.9535\n",
      "Epoch 3/25\n",
      "23/23 [==============================] - 0s 930us/step - loss: 0.0647 - accuracy: 0.9789\n",
      "Epoch 4/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0450 - accuracy: 0.9789\n",
      "Epoch 5/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0427 - accuracy: 0.9746\n",
      "Epoch 6/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0387 - accuracy: 0.9817\n",
      "Epoch 7/25\n",
      "23/23 [==============================] - 0s 930us/step - loss: 0.0362 - accuracy: 0.9817\n",
      "Epoch 8/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0364 - accuracy: 0.9859\n",
      "Epoch 9/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0373 - accuracy: 0.9803\n",
      "Epoch 10/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0420 - accuracy: 0.9831\n",
      "Epoch 11/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0365 - accuracy: 0.9789\n",
      "Epoch 12/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0321 - accuracy: 0.9845\n",
      "Epoch 13/25\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.0346 - accuracy: 0.9789\n",
      "Epoch 14/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0325 - accuracy: 0.9817\n",
      "Epoch 15/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0315 - accuracy: 0.9831\n",
      "Epoch 16/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0309 - accuracy: 0.9831\n",
      "Epoch 17/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0325 - accuracy: 0.9803\n",
      "Epoch 18/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0322 - accuracy: 0.9845\n",
      "Epoch 19/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0293 - accuracy: 0.9803\n",
      "Epoch 20/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0310 - accuracy: 0.9817\n",
      "Epoch 21/25\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.0336 - accuracy: 0.9831\n",
      "Epoch 22/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0303 - accuracy: 0.9817\n",
      "Epoch 23/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0315 - accuracy: 0.9845\n",
      "Epoch 24/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0290 - accuracy: 0.9817\n",
      "Epoch 25/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0299 - accuracy: 0.9803\n",
      "23/23 - 0s - loss: 0.0257 - accuracy: 0.9859 - 102ms/epoch - 4ms/step\n",
      "Loss: 0.025691960006952286, Accuracy: 0.98591548204422\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_116 (Dense)           (None, 100)               8500      \n",
      "                                                                 \n",
      " dense_117 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_118 (Dense)           (None, 25)                1275      \n",
      "                                                                 \n",
      " dense_119 (Dense)           (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,851\n",
      "Trainable params: 14,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.4605 - accuracy: 0.7803\n",
      "Epoch 2/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.2441 - accuracy: 0.9169\n",
      "Epoch 3/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.1370 - accuracy: 0.9634\n",
      "Epoch 4/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0905 - accuracy: 0.9606\n",
      "Epoch 5/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0754 - accuracy: 0.9577\n",
      "Epoch 6/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0691 - accuracy: 0.9732\n",
      "Epoch 7/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0612 - accuracy: 0.9718\n",
      "Epoch 8/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0640 - accuracy: 0.9662\n",
      "Epoch 9/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0700 - accuracy: 0.9634\n",
      "Epoch 10/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0638 - accuracy: 0.9676\n",
      "Epoch 11/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0577 - accuracy: 0.9732\n",
      "Epoch 12/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0586 - accuracy: 0.9676\n",
      "Epoch 13/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0578 - accuracy: 0.9648\n",
      "Epoch 14/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0558 - accuracy: 0.9775\n",
      "Epoch 15/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0560 - accuracy: 0.9732\n",
      "Epoch 16/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0585 - accuracy: 0.9676\n",
      "Epoch 17/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0533 - accuracy: 0.9803\n",
      "Epoch 18/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0566 - accuracy: 0.9676\n",
      "Epoch 19/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0496 - accuracy: 0.9775\n",
      "Epoch 20/25\n",
      "23/23 [==============================] - 0s 906us/step - loss: 0.0499 - accuracy: 0.9803\n",
      "Epoch 21/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0483 - accuracy: 0.9817\n",
      "Epoch 22/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0496 - accuracy: 0.9718\n",
      "Epoch 23/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0547 - accuracy: 0.9718\n",
      "Epoch 24/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0578 - accuracy: 0.9676\n",
      "Epoch 25/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0566 - accuracy: 0.9648\n",
      "23/23 - 0s - loss: 0.0447 - accuracy: 0.9803 - 104ms/epoch - 5ms/step\n",
      "Loss: 0.04466733708977699, Accuracy: 0.9802817106246948\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_120 (Dense)           (None, 100)               8500      \n",
      "                                                                 \n",
      " dense_121 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_122 (Dense)           (None, 25)                1275      \n",
      "                                                                 \n",
      " dense_123 (Dense)           (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,851\n",
      "Trainable params: 14,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.4587 - accuracy: 0.8056\n",
      "Epoch 2/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.2323 - accuracy: 0.9099\n",
      "Epoch 3/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.1279 - accuracy: 0.9549\n",
      "Epoch 4/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0809 - accuracy: 0.9718\n",
      "Epoch 5/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0642 - accuracy: 0.9746\n",
      "Epoch 6/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0676 - accuracy: 0.9789\n",
      "Epoch 7/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0554 - accuracy: 0.9746\n",
      "Epoch 8/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0503 - accuracy: 0.9803\n",
      "Epoch 9/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0504 - accuracy: 0.9803\n",
      "Epoch 10/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0510 - accuracy: 0.9789\n",
      "Epoch 11/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0452 - accuracy: 0.9789\n",
      "Epoch 12/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0416 - accuracy: 0.9831\n",
      "Epoch 13/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0421 - accuracy: 0.9817\n",
      "Epoch 14/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0413 - accuracy: 0.9831\n",
      "Epoch 15/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0420 - accuracy: 0.9803\n",
      "Epoch 16/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0369 - accuracy: 0.9845\n",
      "Epoch 17/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0392 - accuracy: 0.9831\n",
      "Epoch 18/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0364 - accuracy: 0.9859\n",
      "Epoch 19/25\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.0381 - accuracy: 0.9845\n",
      "Epoch 20/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0589 - accuracy: 0.9775\n",
      "Epoch 21/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0556 - accuracy: 0.9704\n",
      "Epoch 22/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0392 - accuracy: 0.9775\n",
      "Epoch 23/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0348 - accuracy: 0.9887\n",
      "Epoch 24/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0331 - accuracy: 0.9859\n",
      "Epoch 25/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0335 - accuracy: 0.9831\n",
      "23/23 - 0s - loss: 0.0295 - accuracy: 0.9887 - 101ms/epoch - 4ms/step\n",
      "Loss: 0.02947895973920822, Accuracy: 0.9887323975563049\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_124 (Dense)           (None, 100)               8500      \n",
      "                                                                 \n",
      " dense_125 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_126 (Dense)           (None, 25)                1275      \n",
      "                                                                 \n",
      " dense_127 (Dense)           (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,851\n",
      "Trainable params: 14,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "23/23 [==============================] - 0s 884us/step - loss: 0.3518 - accuracy: 0.8761\n",
      "Epoch 2/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.1471 - accuracy: 0.9310\n",
      "Epoch 3/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0779 - accuracy: 0.9718\n",
      "Epoch 4/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0543 - accuracy: 0.9775\n",
      "Epoch 5/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0483 - accuracy: 0.9803\n",
      "Epoch 6/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0460 - accuracy: 0.9803\n",
      "Epoch 7/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0450 - accuracy: 0.9775\n",
      "Epoch 8/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0474 - accuracy: 0.9718\n",
      "Epoch 9/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0431 - accuracy: 0.9761\n",
      "Epoch 10/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0502 - accuracy: 0.9704\n",
      "Epoch 11/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0394 - accuracy: 0.9817\n",
      "Epoch 12/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0385 - accuracy: 0.9831\n",
      "Epoch 13/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0383 - accuracy: 0.9803\n",
      "Epoch 14/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0375 - accuracy: 0.9831\n",
      "Epoch 15/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0374 - accuracy: 0.9845\n",
      "Epoch 16/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0388 - accuracy: 0.9845\n",
      "Epoch 17/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0354 - accuracy: 0.9803\n",
      "Epoch 18/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0351 - accuracy: 0.9831\n",
      "Epoch 19/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0363 - accuracy: 0.9803\n",
      "Epoch 20/25\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0406 - accuracy: 0.9789\n",
      "Epoch 21/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0338 - accuracy: 0.9859\n",
      "Epoch 22/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0325 - accuracy: 0.9859\n",
      "Epoch 23/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0355 - accuracy: 0.9789\n",
      "Epoch 24/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0347 - accuracy: 0.9831\n",
      "Epoch 25/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0338 - accuracy: 0.9873\n",
      "23/23 - 0s - loss: 0.0293 - accuracy: 0.9915 - 105ms/epoch - 5ms/step\n",
      "Loss: 0.02932761050760746, Accuracy: 0.9915493130683899\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_128 (Dense)           (None, 100)               8500      \n",
      "                                                                 \n",
      " dense_129 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_130 (Dense)           (None, 25)                1275      \n",
      "                                                                 \n",
      " dense_131 (Dense)           (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,851\n",
      "Trainable params: 14,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.3537 - accuracy: 0.9070\n",
      "Epoch 2/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.1370 - accuracy: 0.9408\n",
      "Epoch 3/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0917 - accuracy: 0.9648\n",
      "Epoch 4/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0701 - accuracy: 0.9775\n",
      "Epoch 5/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0573 - accuracy: 0.9831\n",
      "Epoch 6/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0488 - accuracy: 0.9831\n",
      "Epoch 7/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0440 - accuracy: 0.9831\n",
      "Epoch 8/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0407 - accuracy: 0.9831\n",
      "Epoch 9/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0417 - accuracy: 0.9831\n",
      "Epoch 10/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0398 - accuracy: 0.9817\n",
      "Epoch 11/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0390 - accuracy: 0.9859\n",
      "Epoch 12/25\n",
      "23/23 [==============================] - 0s 884us/step - loss: 0.0380 - accuracy: 0.9845\n",
      "Epoch 13/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0359 - accuracy: 0.9859\n",
      "Epoch 14/25\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0351 - accuracy: 0.9859\n",
      "Epoch 15/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0350 - accuracy: 0.9859\n",
      "Epoch 16/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0324 - accuracy: 0.9887\n",
      "Epoch 17/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0374 - accuracy: 0.9859\n",
      "Epoch 18/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0330 - accuracy: 0.9859\n",
      "Epoch 19/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0317 - accuracy: 0.9845\n",
      "Epoch 20/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0336 - accuracy: 0.9859\n",
      "Epoch 21/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0320 - accuracy: 0.9845\n",
      "Epoch 22/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0406 - accuracy: 0.9803\n",
      "Epoch 23/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0338 - accuracy: 0.9845\n",
      "Epoch 24/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0276 - accuracy: 0.9887\n",
      "Epoch 25/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0269 - accuracy: 0.9887\n",
      "23/23 - 0s - loss: 0.0242 - accuracy: 0.9873 - 108ms/epoch - 5ms/step\n",
      "Loss: 0.024218792095780373, Accuracy: 0.9873239398002625\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_132 (Dense)           (None, 100)               8500      \n",
      "                                                                 \n",
      " dense_133 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_134 (Dense)           (None, 25)                1275      \n",
      "                                                                 \n",
      " dense_135 (Dense)           (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,851\n",
      "Trainable params: 14,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.6011 - accuracy: 0.7268\n",
      "Epoch 2/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2564 - accuracy: 0.9423\n",
      "Epoch 3/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0954 - accuracy: 0.9775\n",
      "Epoch 4/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0500 - accuracy: 0.9901\n",
      "Epoch 5/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0373 - accuracy: 0.9859\n",
      "Epoch 6/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0329 - accuracy: 0.9901\n",
      "Epoch 7/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0315 - accuracy: 0.9831\n",
      "Epoch 8/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0312 - accuracy: 0.9859\n",
      "Epoch 9/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0363 - accuracy: 0.9845\n",
      "Epoch 10/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0284 - accuracy: 0.9873\n",
      "Epoch 11/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0301 - accuracy: 0.9873\n",
      "Epoch 12/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0274 - accuracy: 0.9901\n",
      "Epoch 13/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0274 - accuracy: 0.9873\n",
      "Epoch 14/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0330 - accuracy: 0.9845\n",
      "Epoch 15/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0298 - accuracy: 0.9831\n",
      "Epoch 16/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0298 - accuracy: 0.9901\n",
      "Epoch 17/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0260 - accuracy: 0.9901\n",
      "Epoch 18/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0253 - accuracy: 0.9873\n",
      "Epoch 19/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0331 - accuracy: 0.9831\n",
      "Epoch 20/25\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.0255 - accuracy: 0.9859\n",
      "Epoch 21/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0252 - accuracy: 0.9873\n",
      "Epoch 22/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0248 - accuracy: 0.9901\n",
      "Epoch 23/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0230 - accuracy: 0.9901\n",
      "Epoch 24/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0237 - accuracy: 0.9873\n",
      "Epoch 25/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0228 - accuracy: 0.9901\n",
      "23/23 - 0s - loss: 0.0198 - accuracy: 0.9901 - 101ms/epoch - 4ms/step\n",
      "Loss: 0.019757576286792755, Accuracy: 0.9901408553123474\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_136 (Dense)           (None, 100)               8500      \n",
      "                                                                 \n",
      " dense_137 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_138 (Dense)           (None, 25)                1275      \n",
      "                                                                 \n",
      " dense_139 (Dense)           (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,851\n",
      "Trainable params: 14,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.4838 - accuracy: 0.7803\n",
      "Epoch 2/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.2050 - accuracy: 0.9254\n",
      "Epoch 3/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.1144 - accuracy: 0.9549\n",
      "Epoch 4/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0776 - accuracy: 0.9690\n",
      "Epoch 5/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0605 - accuracy: 0.9789\n",
      "Epoch 6/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0585 - accuracy: 0.9732\n",
      "Epoch 7/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0553 - accuracy: 0.9761\n",
      "Epoch 8/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0526 - accuracy: 0.9775\n",
      "Epoch 9/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0516 - accuracy: 0.9789\n",
      "Epoch 10/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0481 - accuracy: 0.9761\n",
      "Epoch 11/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0469 - accuracy: 0.9775\n",
      "Epoch 12/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0425 - accuracy: 0.9831\n",
      "Epoch 13/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0404 - accuracy: 0.9845\n",
      "Epoch 14/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0420 - accuracy: 0.9831\n",
      "Epoch 15/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0459 - accuracy: 0.9789\n",
      "Epoch 16/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0403 - accuracy: 0.9817\n",
      "Epoch 17/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0384 - accuracy: 0.9803\n",
      "Epoch 18/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0388 - accuracy: 0.9845\n",
      "Epoch 19/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0392 - accuracy: 0.9845\n",
      "Epoch 20/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0381 - accuracy: 0.9817\n",
      "Epoch 21/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0369 - accuracy: 0.9845\n",
      "Epoch 22/25\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.0375 - accuracy: 0.9803\n",
      "Epoch 23/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0534 - accuracy: 0.9761\n",
      "Epoch 24/25\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.0440 - accuracy: 0.9775\n",
      "Epoch 25/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0358 - accuracy: 0.9845\n",
      "23/23 - 0s - loss: 0.0307 - accuracy: 0.9859 - 109ms/epoch - 5ms/step\n",
      "Loss: 0.030704457312822342, Accuracy: 0.98591548204422\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_140 (Dense)           (None, 100)               8500      \n",
      "                                                                 \n",
      " dense_141 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_142 (Dense)           (None, 25)                1275      \n",
      "                                                                 \n",
      " dense_143 (Dense)           (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,851\n",
      "Trainable params: 14,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.2977 - accuracy: 0.8620\n",
      "Epoch 2/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.1464 - accuracy: 0.9437\n",
      "Epoch 3/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0925 - accuracy: 0.9704\n",
      "Epoch 4/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0764 - accuracy: 0.9648\n",
      "Epoch 5/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0708 - accuracy: 0.9732\n",
      "Epoch 6/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0668 - accuracy: 0.9690\n",
      "Epoch 7/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0644 - accuracy: 0.9704\n",
      "Epoch 8/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0653 - accuracy: 0.9704\n",
      "Epoch 9/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0590 - accuracy: 0.9718\n",
      "Epoch 10/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0613 - accuracy: 0.9746\n",
      "Epoch 11/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0665 - accuracy: 0.9676\n",
      "Epoch 12/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0575 - accuracy: 0.9732\n",
      "Epoch 13/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0615 - accuracy: 0.9690\n",
      "Epoch 14/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0535 - accuracy: 0.9704\n",
      "Epoch 15/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0569 - accuracy: 0.9704\n",
      "Epoch 16/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0556 - accuracy: 0.9732\n",
      "Epoch 17/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0561 - accuracy: 0.9704\n",
      "Epoch 18/25\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.0525 - accuracy: 0.9761\n",
      "Epoch 19/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0592 - accuracy: 0.9620\n",
      "Epoch 20/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0496 - accuracy: 0.9732\n",
      "Epoch 21/25\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.0518 - accuracy: 0.9704\n",
      "Epoch 22/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0511 - accuracy: 0.9746\n",
      "Epoch 23/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0487 - accuracy: 0.9803\n",
      "Epoch 24/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0509 - accuracy: 0.9732\n",
      "Epoch 25/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0499 - accuracy: 0.9732\n",
      "23/23 - 0s - loss: 0.0422 - accuracy: 0.9775 - 102ms/epoch - 4ms/step\n",
      "Loss: 0.04216915741562843, Accuracy: 0.9774647951126099\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_144 (Dense)           (None, 100)               8500      \n",
      "                                                                 \n",
      " dense_145 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_146 (Dense)           (None, 25)                1275      \n",
      "                                                                 \n",
      " dense_147 (Dense)           (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,851\n",
      "Trainable params: 14,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.5149 - accuracy: 0.7211\n",
      "Epoch 2/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1909 - accuracy: 0.9056\n",
      "Epoch 3/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.1027 - accuracy: 0.9634\n",
      "Epoch 4/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0639 - accuracy: 0.9803\n",
      "Epoch 5/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0499 - accuracy: 0.9761\n",
      "Epoch 6/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0447 - accuracy: 0.9831\n",
      "Epoch 7/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0407 - accuracy: 0.9803\n",
      "Epoch 8/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0403 - accuracy: 0.9831\n",
      "Epoch 9/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0361 - accuracy: 0.9817\n",
      "Epoch 10/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0379 - accuracy: 0.9845\n",
      "Epoch 11/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0359 - accuracy: 0.9803\n",
      "Epoch 12/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0315 - accuracy: 0.9873\n",
      "Epoch 13/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0319 - accuracy: 0.9817\n",
      "Epoch 14/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0306 - accuracy: 0.9845\n",
      "Epoch 15/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0321 - accuracy: 0.9859\n",
      "Epoch 16/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0295 - accuracy: 0.9873\n",
      "Epoch 17/25\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0286 - accuracy: 0.9873\n",
      "Epoch 18/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0362 - accuracy: 0.9845\n",
      "Epoch 19/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0330 - accuracy: 0.9845\n",
      "Epoch 20/25\n",
      "23/23 [==============================] - 0s 884us/step - loss: 0.0298 - accuracy: 0.9901\n",
      "Epoch 21/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0280 - accuracy: 0.9873\n",
      "Epoch 22/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0262 - accuracy: 0.9901\n",
      "Epoch 23/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0311 - accuracy: 0.9859\n",
      "Epoch 24/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0351 - accuracy: 0.9803\n",
      "Epoch 25/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0326 - accuracy: 0.9859\n",
      "23/23 - 0s - loss: 0.0251 - accuracy: 0.9901 - 102ms/epoch - 4ms/step\n",
      "Loss: 0.025054510682821274, Accuracy: 0.9901408553123474\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_148 (Dense)           (None, 100)               8500      \n",
      "                                                                 \n",
      " dense_149 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_150 (Dense)           (None, 25)                1275      \n",
      "                                                                 \n",
      " dense_151 (Dense)           (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,851\n",
      "Trainable params: 14,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "23/23 [==============================] - 1s 907us/step - loss: 0.5135 - accuracy: 0.7479\n",
      "Epoch 2/25\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.2612 - accuracy: 0.9042\n",
      "Epoch 3/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.1499 - accuracy: 0.9465\n",
      "Epoch 4/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.1123 - accuracy: 0.9577\n",
      "Epoch 5/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0965 - accuracy: 0.9620\n",
      "Epoch 6/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0855 - accuracy: 0.9704\n",
      "Epoch 7/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0874 - accuracy: 0.9592\n",
      "Epoch 8/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0791 - accuracy: 0.9662\n",
      "Epoch 9/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0869 - accuracy: 0.9620\n",
      "Epoch 10/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0745 - accuracy: 0.9690\n",
      "Epoch 11/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0755 - accuracy: 0.9690\n",
      "Epoch 12/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0741 - accuracy: 0.9662\n",
      "Epoch 13/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0718 - accuracy: 0.9732\n",
      "Epoch 14/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0677 - accuracy: 0.9676\n",
      "Epoch 15/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0745 - accuracy: 0.9690\n",
      "Epoch 16/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0710 - accuracy: 0.9690\n",
      "Epoch 17/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0730 - accuracy: 0.9662\n",
      "Epoch 18/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0648 - accuracy: 0.9718\n",
      "Epoch 19/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0696 - accuracy: 0.9718\n",
      "Epoch 20/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0614 - accuracy: 0.9704\n",
      "Epoch 21/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0673 - accuracy: 0.9662\n",
      "Epoch 22/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0663 - accuracy: 0.9648\n",
      "Epoch 23/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0582 - accuracy: 0.9704\n",
      "Epoch 24/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0657 - accuracy: 0.9704\n",
      "Epoch 25/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0618 - accuracy: 0.9704\n",
      "23/23 - 0s - loss: 0.0523 - accuracy: 0.9732 - 103ms/epoch - 4ms/step\n",
      "Loss: 0.05233294144272804, Accuracy: 0.9732394218444824\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_152 (Dense)           (None, 100)               8500      \n",
      "                                                                 \n",
      " dense_153 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_154 (Dense)           (None, 25)                1275      \n",
      "                                                                 \n",
      " dense_155 (Dense)           (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,851\n",
      "Trainable params: 14,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.4580 - accuracy: 0.8014\n",
      "Epoch 2/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2026 - accuracy: 0.9352\n",
      "Epoch 3/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1064 - accuracy: 0.9676\n",
      "Epoch 4/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0762 - accuracy: 0.9676\n",
      "Epoch 5/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0642 - accuracy: 0.9746\n",
      "Epoch 6/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0572 - accuracy: 0.9761\n",
      "Epoch 7/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0588 - accuracy: 0.9789\n",
      "Epoch 8/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0614 - accuracy: 0.9746\n",
      "Epoch 9/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0480 - accuracy: 0.9845\n",
      "Epoch 10/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0493 - accuracy: 0.9775\n",
      "Epoch 11/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0445 - accuracy: 0.9803\n",
      "Epoch 12/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0449 - accuracy: 0.9775\n",
      "Epoch 13/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0448 - accuracy: 0.9789\n",
      "Epoch 14/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0460 - accuracy: 0.9775\n",
      "Epoch 15/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0463 - accuracy: 0.9761\n",
      "Epoch 16/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0495 - accuracy: 0.9803\n",
      "Epoch 17/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0487 - accuracy: 0.9803\n",
      "Epoch 18/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0566 - accuracy: 0.9718\n",
      "Epoch 19/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0449 - accuracy: 0.9845\n",
      "Epoch 20/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0407 - accuracy: 0.9817\n",
      "Epoch 21/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0374 - accuracy: 0.9845\n",
      "Epoch 22/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0366 - accuracy: 0.9845\n",
      "Epoch 23/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0373 - accuracy: 0.9845\n",
      "Epoch 24/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0381 - accuracy: 0.9817\n",
      "Epoch 25/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0424 - accuracy: 0.9845\n",
      "23/23 - 0s - loss: 0.0361 - accuracy: 0.9803 - 100ms/epoch - 4ms/step\n",
      "Loss: 0.03608153760433197, Accuracy: 0.9802817106246948\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_156 (Dense)           (None, 100)               8500      \n",
      "                                                                 \n",
      " dense_157 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_158 (Dense)           (None, 25)                1275      \n",
      "                                                                 \n",
      " dense_159 (Dense)           (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,851\n",
      "Trainable params: 14,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.3668 - accuracy: 0.8493\n",
      "Epoch 2/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1228 - accuracy: 0.9563\n",
      "Epoch 3/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0586 - accuracy: 0.9789\n",
      "Epoch 4/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0434 - accuracy: 0.9873\n",
      "Epoch 5/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0372 - accuracy: 0.9873\n",
      "Epoch 6/25\n",
      "23/23 [==============================] - 0s 930us/step - loss: 0.0373 - accuracy: 0.9817\n",
      "Epoch 7/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0325 - accuracy: 0.9859\n",
      "Epoch 8/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0322 - accuracy: 0.9873\n",
      "Epoch 9/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0302 - accuracy: 0.9845\n",
      "Epoch 10/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0300 - accuracy: 0.9831\n",
      "Epoch 11/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0336 - accuracy: 0.9831\n",
      "Epoch 12/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0286 - accuracy: 0.9915\n",
      "Epoch 13/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0259 - accuracy: 0.9887\n",
      "Epoch 14/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0259 - accuracy: 0.9873\n",
      "Epoch 15/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0251 - accuracy: 0.9901\n",
      "Epoch 16/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0268 - accuracy: 0.9873\n",
      "Epoch 17/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0260 - accuracy: 0.9859\n",
      "Epoch 18/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0274 - accuracy: 0.9887\n",
      "Epoch 19/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0264 - accuracy: 0.9873\n",
      "Epoch 20/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0227 - accuracy: 0.9915\n",
      "Epoch 21/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0232 - accuracy: 0.9873\n",
      "Epoch 22/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0239 - accuracy: 0.9873\n",
      "Epoch 23/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0228 - accuracy: 0.9887\n",
      "Epoch 24/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0205 - accuracy: 0.9901\n",
      "Epoch 25/25\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.0202 - accuracy: 0.9901\n",
      "23/23 - 0s - loss: 0.0164 - accuracy: 0.9944 - 105ms/epoch - 5ms/step\n",
      "Loss: 0.016389647498726845, Accuracy: 0.9943661689758301\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_160 (Dense)           (None, 100)               8500      \n",
      "                                                                 \n",
      " dense_161 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_162 (Dense)           (None, 25)                1275      \n",
      "                                                                 \n",
      " dense_163 (Dense)           (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,851\n",
      "Trainable params: 14,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.4008 - accuracy: 0.8254\n",
      "Epoch 2/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1372 - accuracy: 0.9549\n",
      "Epoch 3/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0626 - accuracy: 0.9789\n",
      "Epoch 4/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0456 - accuracy: 0.9831\n",
      "Epoch 5/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0415 - accuracy: 0.9859\n",
      "Epoch 6/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0381 - accuracy: 0.9845\n",
      "Epoch 7/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0351 - accuracy: 0.9845\n",
      "Epoch 8/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0346 - accuracy: 0.9817\n",
      "Epoch 9/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0326 - accuracy: 0.9845\n",
      "Epoch 10/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0346 - accuracy: 0.9817\n",
      "Epoch 11/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0321 - accuracy: 0.9859\n",
      "Epoch 12/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0307 - accuracy: 0.9817\n",
      "Epoch 13/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0312 - accuracy: 0.9789\n",
      "Epoch 14/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0298 - accuracy: 0.9803\n",
      "Epoch 15/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0283 - accuracy: 0.9831\n",
      "Epoch 16/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0298 - accuracy: 0.9831\n",
      "Epoch 17/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0300 - accuracy: 0.9831\n",
      "Epoch 18/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0281 - accuracy: 0.9817\n",
      "Epoch 19/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0304 - accuracy: 0.9817\n",
      "Epoch 20/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0277 - accuracy: 0.9803\n",
      "Epoch 21/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0286 - accuracy: 0.9845\n",
      "Epoch 22/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0275 - accuracy: 0.9831\n",
      "Epoch 23/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0313 - accuracy: 0.9817\n",
      "Epoch 24/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0266 - accuracy: 0.9817\n",
      "Epoch 25/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0329 - accuracy: 0.9817\n",
      "23/23 - 0s - loss: 0.0236 - accuracy: 0.9831 - 103ms/epoch - 4ms/step\n",
      "Loss: 0.02361689880490303, Accuracy: 0.983098566532135\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_164 (Dense)           (None, 100)               8500      \n",
      "                                                                 \n",
      " dense_165 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_166 (Dense)           (None, 25)                1275      \n",
      "                                                                 \n",
      " dense_167 (Dense)           (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,851\n",
      "Trainable params: 14,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.3911 - accuracy: 0.8394\n",
      "Epoch 2/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2463 - accuracy: 0.8873\n",
      "Epoch 3/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1797 - accuracy: 0.9268\n",
      "Epoch 4/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1417 - accuracy: 0.9479\n",
      "Epoch 5/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1179 - accuracy: 0.9535\n",
      "Epoch 6/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1101 - accuracy: 0.9549\n",
      "Epoch 7/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1046 - accuracy: 0.9423\n",
      "Epoch 8/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0966 - accuracy: 0.9606\n",
      "Epoch 9/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0914 - accuracy: 0.9662\n",
      "Epoch 10/25\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0913 - accuracy: 0.9549\n",
      "Epoch 11/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0865 - accuracy: 0.9634\n",
      "Epoch 12/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1014 - accuracy: 0.9563\n",
      "Epoch 13/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0907 - accuracy: 0.9521\n",
      "Epoch 14/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0758 - accuracy: 0.9648\n",
      "Epoch 15/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0772 - accuracy: 0.9648\n",
      "Epoch 16/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0773 - accuracy: 0.9634\n",
      "Epoch 17/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0739 - accuracy: 0.9676\n",
      "Epoch 18/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0723 - accuracy: 0.9662\n",
      "Epoch 19/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0677 - accuracy: 0.9690\n",
      "Epoch 20/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0753 - accuracy: 0.9662\n",
      "Epoch 21/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0685 - accuracy: 0.9606\n",
      "Epoch 22/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0687 - accuracy: 0.9662\n",
      "Epoch 23/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0674 - accuracy: 0.9676\n",
      "Epoch 24/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0668 - accuracy: 0.9690\n",
      "Epoch 25/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0669 - accuracy: 0.9662\n",
      "23/23 - 0s - loss: 0.0586 - accuracy: 0.9704 - 103ms/epoch - 4ms/step\n",
      "Loss: 0.058555684983730316, Accuracy: 0.9704225063323975\n",
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_168 (Dense)           (None, 100)               8500      \n",
      "                                                                 \n",
      " dense_169 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_170 (Dense)           (None, 25)                1275      \n",
      "                                                                 \n",
      " dense_171 (Dense)           (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,851\n",
      "Trainable params: 14,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.5674 - accuracy: 0.6972\n",
      "Epoch 2/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3874 - accuracy: 0.8014\n",
      "Epoch 3/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2599 - accuracy: 0.9056\n",
      "Epoch 4/25\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.9338\n",
      "Epoch 5/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1518 - accuracy: 0.9479\n",
      "Epoch 6/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1485 - accuracy: 0.9338\n",
      "Epoch 7/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1348 - accuracy: 0.9423\n",
      "Epoch 8/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1251 - accuracy: 0.9465\n",
      "Epoch 9/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1242 - accuracy: 0.9451\n",
      "Epoch 10/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1236 - accuracy: 0.9465\n",
      "Epoch 11/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1212 - accuracy: 0.9451\n",
      "Epoch 12/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1286 - accuracy: 0.9366\n",
      "Epoch 13/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.1165 - accuracy: 0.9535\n",
      "Epoch 14/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.1114 - accuracy: 0.9493\n",
      "Epoch 15/25\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1125 - accuracy: 0.9408\n",
      "Epoch 16/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.1125 - accuracy: 0.9507\n",
      "Epoch 17/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1052 - accuracy: 0.9563\n",
      "Epoch 18/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1088 - accuracy: 0.9479\n",
      "Epoch 19/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0999 - accuracy: 0.9521\n",
      "Epoch 20/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0961 - accuracy: 0.9577\n",
      "Epoch 21/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1009 - accuracy: 0.9521\n",
      "Epoch 22/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0968 - accuracy: 0.9549\n",
      "Epoch 23/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0986 - accuracy: 0.9535\n",
      "Epoch 24/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0945 - accuracy: 0.9535\n",
      "Epoch 25/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1009 - accuracy: 0.9549\n",
      "23/23 - 0s - loss: 0.0834 - accuracy: 0.9634 - 117ms/epoch - 5ms/step\n",
      "Loss: 0.08341483026742935, Accuracy: 0.9633802771568298\n",
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_172 (Dense)           (None, 100)               8500      \n",
      "                                                                 \n",
      " dense_173 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_174 (Dense)           (None, 25)                1275      \n",
      "                                                                 \n",
      " dense_175 (Dense)           (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,851\n",
      "Trainable params: 14,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "23/23 [==============================] - 0s 884us/step - loss: 0.4620 - accuracy: 0.8014\n",
      "Epoch 2/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2438 - accuracy: 0.9056\n",
      "Epoch 3/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.1589 - accuracy: 0.9423\n",
      "Epoch 4/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1275 - accuracy: 0.9592\n",
      "Epoch 5/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1173 - accuracy: 0.9521\n",
      "Epoch 6/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.1158 - accuracy: 0.9507\n",
      "Epoch 7/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.1067 - accuracy: 0.9549\n",
      "Epoch 8/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.1029 - accuracy: 0.9577\n",
      "Epoch 9/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1030 - accuracy: 0.9592\n",
      "Epoch 10/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1042 - accuracy: 0.9592\n",
      "Epoch 11/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1024 - accuracy: 0.9549\n",
      "Epoch 12/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.1006 - accuracy: 0.9535\n",
      "Epoch 13/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1041 - accuracy: 0.9507\n",
      "Epoch 14/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0999 - accuracy: 0.9521\n",
      "Epoch 15/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0945 - accuracy: 0.9606\n",
      "Epoch 16/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1058 - accuracy: 0.9479\n",
      "Epoch 17/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0986 - accuracy: 0.9535\n",
      "Epoch 18/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0933 - accuracy: 0.9662\n",
      "Epoch 19/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0953 - accuracy: 0.9535\n",
      "Epoch 20/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0884 - accuracy: 0.9592\n",
      "Epoch 21/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0882 - accuracy: 0.9620\n",
      "Epoch 22/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0888 - accuracy: 0.9648\n",
      "Epoch 23/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0878 - accuracy: 0.9606\n",
      "Epoch 24/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0881 - accuracy: 0.9592\n",
      "Epoch 25/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0853 - accuracy: 0.9620\n",
      "23/23 - 0s - loss: 0.0766 - accuracy: 0.9676 - 410ms/epoch - 18ms/step\n",
      "Loss: 0.07659735530614853, Accuracy: 0.9676056504249573\n",
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_176 (Dense)           (None, 100)               8500      \n",
      "                                                                 \n",
      " dense_177 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_178 (Dense)           (None, 25)                1275      \n",
      "                                                                 \n",
      " dense_179 (Dense)           (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,851\n",
      "Trainable params: 14,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "23/23 [==============================] - 1s 2ms/step - loss: 0.4691 - accuracy: 0.8169\n",
      "Epoch 2/25\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1895 - accuracy: 0.9465\n",
      "Epoch 3/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0974 - accuracy: 0.9676\n",
      "Epoch 4/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0704 - accuracy: 0.9718\n",
      "Epoch 5/25\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 0.9732\n",
      "Epoch 6/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0611 - accuracy: 0.9746\n",
      "Epoch 7/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0622 - accuracy: 0.9761\n",
      "Epoch 8/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0625 - accuracy: 0.9761\n",
      "Epoch 9/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0604 - accuracy: 0.9761\n",
      "Epoch 10/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0582 - accuracy: 0.9676\n",
      "Epoch 11/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0537 - accuracy: 0.9761\n",
      "Epoch 12/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0587 - accuracy: 0.9704\n",
      "Epoch 13/25\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0538 - accuracy: 0.9746\n",
      "Epoch 14/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0525 - accuracy: 0.9732\n",
      "Epoch 15/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0480 - accuracy: 0.9746\n",
      "Epoch 16/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0536 - accuracy: 0.9732\n",
      "Epoch 17/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0492 - accuracy: 0.9761\n",
      "Epoch 18/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0485 - accuracy: 0.9761\n",
      "Epoch 19/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0503 - accuracy: 0.9789\n",
      "Epoch 20/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0497 - accuracy: 0.9789\n",
      "Epoch 21/25\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0462 - accuracy: 0.9761\n",
      "Epoch 22/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0463 - accuracy: 0.9803\n",
      "Epoch 23/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0445 - accuracy: 0.9775\n",
      "Epoch 24/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0448 - accuracy: 0.9789\n",
      "Epoch 25/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0448 - accuracy: 0.9817\n",
      "23/23 - 0s - loss: 0.0401 - accuracy: 0.9803 - 105ms/epoch - 5ms/step\n",
      "Loss: 0.04009450227022171, Accuracy: 0.9802817106246948\n",
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_180 (Dense)           (None, 100)               8500      \n",
      "                                                                 \n",
      " dense_181 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_182 (Dense)           (None, 25)                1275      \n",
      "                                                                 \n",
      " dense_183 (Dense)           (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,851\n",
      "Trainable params: 14,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2146 - accuracy: 0.9380\n",
      "Epoch 2/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0600 - accuracy: 0.9676\n",
      "Epoch 3/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0306 - accuracy: 0.9972\n",
      "Epoch 4/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0187 - accuracy: 0.9972\n",
      "Epoch 5/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0111 - accuracy: 0.9972\n",
      "Epoch 6/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0076 - accuracy: 0.9972\n",
      "Epoch 7/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0064 - accuracy: 0.9958\n",
      "Epoch 8/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0061 - accuracy: 0.9972\n",
      "Epoch 9/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0059 - accuracy: 0.9972\n",
      "Epoch 10/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0070 - accuracy: 0.9972\n",
      "Epoch 11/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0056 - accuracy: 0.9986\n",
      "Epoch 12/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0111 - accuracy: 0.9972\n",
      "Epoch 13/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0065 - accuracy: 0.9972\n",
      "Epoch 14/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0053 - accuracy: 0.9958\n",
      "Epoch 15/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0050 - accuracy: 0.9958\n",
      "Epoch 16/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0047 - accuracy: 0.9972\n",
      "Epoch 17/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0045 - accuracy: 0.9958\n",
      "Epoch 18/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0045 - accuracy: 0.9958\n",
      "Epoch 19/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0044 - accuracy: 0.9972\n",
      "Epoch 20/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0040 - accuracy: 0.9972\n",
      "Epoch 21/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0053 - accuracy: 0.9958\n",
      "Epoch 22/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0040 - accuracy: 0.9972\n",
      "Epoch 23/25\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 0.9958\n",
      "Epoch 24/25\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 0.9958\n",
      "Epoch 25/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0044 - accuracy: 0.9986\n",
      "23/23 - 0s - loss: 0.0036 - accuracy: 0.9986 - 125ms/epoch - 5ms/step\n",
      "Loss: 0.0036367198918014765, Accuracy: 0.9985915422439575\n",
      "Model: \"sequential_46\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_184 (Dense)           (None, 100)               8500      \n",
      "                                                                 \n",
      " dense_185 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_186 (Dense)           (None, 25)                1275      \n",
      "                                                                 \n",
      " dense_187 (Dense)           (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,851\n",
      "Trainable params: 14,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.4102 - accuracy: 0.8648\n",
      "Epoch 2/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1646 - accuracy: 0.9394\n",
      "Epoch 3/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.1122 - accuracy: 0.9394\n",
      "Epoch 4/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0806 - accuracy: 0.9606\n",
      "Epoch 5/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0639 - accuracy: 0.9845\n",
      "Epoch 6/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0484 - accuracy: 0.9873\n",
      "Epoch 7/25\n",
      "23/23 [==============================] - 0s 975us/step - loss: 0.0378 - accuracy: 0.9845\n",
      "Epoch 8/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0302 - accuracy: 0.9887\n",
      "Epoch 9/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0273 - accuracy: 0.9887\n",
      "Epoch 10/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0267 - accuracy: 0.9859\n",
      "Epoch 11/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0237 - accuracy: 0.9901\n",
      "Epoch 12/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0258 - accuracy: 0.9887\n",
      "Epoch 13/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0235 - accuracy: 0.9915\n",
      "Epoch 14/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0217 - accuracy: 0.9873\n",
      "Epoch 15/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0213 - accuracy: 0.9915\n",
      "Epoch 16/25\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.0222 - accuracy: 0.9887\n",
      "Epoch 17/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0211 - accuracy: 0.9873\n",
      "Epoch 18/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.0208 - accuracy: 0.9901\n",
      "Epoch 19/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0173 - accuracy: 0.9944\n",
      "Epoch 20/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0171 - accuracy: 0.9944\n",
      "Epoch 21/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0168 - accuracy: 0.9915\n",
      "Epoch 22/25\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0169 - accuracy: 0.9944\n",
      "Epoch 23/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0164 - accuracy: 0.9915\n",
      "Epoch 24/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0160 - accuracy: 0.9930\n",
      "Epoch 25/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.0155 - accuracy: 0.9944\n",
      "23/23 - 0s - loss: 0.0138 - accuracy: 0.9944 - 134ms/epoch - 6ms/step\n",
      "Loss: 0.013755527324974537, Accuracy: 0.9943661689758301\n",
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_188 (Dense)           (None, 100)               8500      \n",
      "                                                                 \n",
      " dense_189 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_190 (Dense)           (None, 25)                1275      \n",
      "                                                                 \n",
      " dense_191 (Dense)           (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,851\n",
      "Trainable params: 14,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4731 - accuracy: 0.7887\n",
      "Epoch 2/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2868 - accuracy: 0.8873\n",
      "Epoch 3/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2144 - accuracy: 0.9169\n",
      "Epoch 4/25\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1861 - accuracy: 0.9254\n",
      "Epoch 5/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1816 - accuracy: 0.9268\n",
      "Epoch 6/25\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1742 - accuracy: 0.9211\n",
      "Epoch 7/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1670 - accuracy: 0.9225\n",
      "Epoch 8/25\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1615 - accuracy: 0.9324\n",
      "Epoch 9/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1697 - accuracy: 0.9239\n",
      "Epoch 10/25\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1562 - accuracy: 0.9324\n",
      "Epoch 11/25\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1530 - accuracy: 0.9296\n",
      "Epoch 12/25\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1514 - accuracy: 0.9296\n",
      "Epoch 13/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1475 - accuracy: 0.9338\n",
      "Epoch 14/25\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1484 - accuracy: 0.9338\n",
      "Epoch 15/25\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1394 - accuracy: 0.9380\n",
      "Epoch 16/25\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1386 - accuracy: 0.9338\n",
      "Epoch 17/25\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1406 - accuracy: 0.9296\n",
      "Epoch 18/25\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1369 - accuracy: 0.9366\n",
      "Epoch 19/25\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1334 - accuracy: 0.9380\n",
      "Epoch 20/25\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1317 - accuracy: 0.9338\n",
      "Epoch 21/25\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1353 - accuracy: 0.9324\n",
      "Epoch 22/25\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1291 - accuracy: 0.9408\n",
      "Epoch 23/25\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1316 - accuracy: 0.9394\n",
      "Epoch 24/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1252 - accuracy: 0.9408\n",
      "Epoch 25/25\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1264 - accuracy: 0.9352\n",
      "23/23 - 0s - loss: 0.1174 - accuracy: 0.9493 - 132ms/epoch - 6ms/step\n",
      "Loss: 0.11743098497390747, Accuracy: 0.9492957592010498\n",
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_192 (Dense)           (None, 100)               8500      \n",
      "                                                                 \n",
      " dense_193 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_194 (Dense)           (None, 25)                1275      \n",
      "                                                                 \n",
      " dense_195 (Dense)           (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,851\n",
      "Trainable params: 14,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.5722 - accuracy: 0.7366\n",
      "Epoch 2/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.3823 - accuracy: 0.8915\n",
      "Epoch 3/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2576 - accuracy: 0.9183\n",
      "Epoch 4/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.2065 - accuracy: 0.9254\n",
      "Epoch 5/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1765 - accuracy: 0.9310\n",
      "Epoch 6/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1681 - accuracy: 0.9296\n",
      "Epoch 7/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1772 - accuracy: 0.9254\n",
      "Epoch 8/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.1624 - accuracy: 0.9324\n",
      "Epoch 9/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1566 - accuracy: 0.9296\n",
      "Epoch 10/25\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1498 - accuracy: 0.9423\n",
      "Epoch 11/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.1483 - accuracy: 0.9310\n",
      "Epoch 12/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1515 - accuracy: 0.9338\n",
      "Epoch 13/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1398 - accuracy: 0.9423\n",
      "Epoch 14/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1401 - accuracy: 0.9366\n",
      "Epoch 15/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1397 - accuracy: 0.9394\n",
      "Epoch 16/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1367 - accuracy: 0.9465\n",
      "Epoch 17/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1355 - accuracy: 0.9465\n",
      "Epoch 18/25\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1357 - accuracy: 0.9493\n",
      "Epoch 19/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1391 - accuracy: 0.9451\n",
      "Epoch 20/25\n",
      "23/23 [==============================] - 0s 997us/step - loss: 0.1316 - accuracy: 0.9479\n",
      "Epoch 21/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1399 - accuracy: 0.9324\n",
      "Epoch 22/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1279 - accuracy: 0.9423\n",
      "Epoch 23/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1208 - accuracy: 0.9451\n",
      "Epoch 24/25\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.1235 - accuracy: 0.9380\n",
      "Epoch 25/25\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.1263 - accuracy: 0.9380\n",
      "23/23 - 0s - loss: 0.1096 - accuracy: 0.9493 - 117ms/epoch - 5ms/step\n",
      "Loss: 0.10956085473299026, Accuracy: 0.9492957592010498\n",
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_196 (Dense)           (None, 100)               8500      \n",
      "                                                                 \n",
      " dense_197 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_198 (Dense)           (None, 25)                1275      \n",
      "                                                                 \n",
      " dense_199 (Dense)           (None, 1)                 26        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,851\n",
      "Trainable params: 14,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Creating data models for each target based on the complete data from 2011 to 2020\n",
    "\n",
    "for target in target_list:\n",
    "    y=df_train[target]\n",
    "\n",
    "    #Build Dense layers for neural network\n",
    "    nn_model = tf.keras.models.Sequential()\n",
    "    nn_model.add(tf.keras.layers.Dense(units=100, activation=\"relu\", input_dim=84))\n",
    "    nn_model.add(tf.keras.layers.Dense(units=50, activation=\"relu\"))\n",
    "    nn_model.add(tf.keras.layers.Dense(units=25, activation=\"relu\"))\n",
    "    nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "    # Compile the Sequential model together and customize metrics\n",
    "    nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "    # Train the model\n",
    "    fit_model = nn_model.fit(X_scaled, y, epochs=25)\n",
    "\n",
    "    # Evaluate the model\n",
    "    model_loss, model_accuracy = nn_model.evaluate(X_scaled, y ,verbose=2)\n",
    "    print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "    print(nn_model.summary())\n",
    "    nn_model.save(\"./Models/\"+ target +\"_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 998us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0    71\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the last model created\n",
    "\n",
    "y_eval = pd.DataFrame(nn_model.predict(df_eval[columns_list]))\n",
    "y_eval.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load specific model\n",
    "model = keras.models.load_model('./Models/affordability_home_30yr_Payment_20_Perc_Down_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale evaluation data\n",
    "\n",
    "X = df_eval[columns_list]\n",
    "scaler = StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9.999812e-01    3\n",
       "5.008881e-07    1\n",
       "9.999697e-01    1\n",
       "9.999777e-01    1\n",
       "9.999763e-01    1\n",
       "               ..\n",
       "9.999219e-01    1\n",
       "9.999271e-01    1\n",
       "9.999295e-01    1\n",
       "9.999316e-01    1\n",
       "9.999968e-01    1\n",
       "Length: 69, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the affordability using the chosen model\n",
    "\n",
    "y_eval = pd.DataFrame(model.predict(X_scaled))\n",
    "y_eval.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the affordability by city\n",
    "\n",
    "plt.scatter(df_eval[\"Identifier\"], y_eval)\n",
    "plt.title(\"Model Predicted Affordability by City\")\n",
    "plt.xlabel(\"City Rank\")\n",
    "plt.ylabel(\"Predicited Affordability\")\n",
    "fig1 = plt.figure(figsize=(20,10))\n",
    "fig1.savefig('./Models/y_eval.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a predictions list\n",
    "predictions = y_eval.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mattw\\AppData\\Local\\Temp\\ipykernel_29908\\78421546.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_eval['Predictions'] = predictions\n"
     ]
    }
   ],
   "source": [
    "# Add model predictions to the evaluation dataset\n",
    "df_eval['Predictions'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Identifier</th>\n",
       "      <th>City_Rank_by_Population(2021)</th>\n",
       "      <th>State</th>\n",
       "      <th>State_abbreviation</th>\n",
       "      <th>Observation_Date</th>\n",
       "      <th>Single_Family_Median_Typical_Home_Value</th>\n",
       "      <th>One_Bedroom_Median_Typical_Home_Value</th>\n",
       "      <th>Two_Bedroom_Median_Typical_Home_Value</th>\n",
       "      <th>Three_Bedroom_Median_Typical_Home_Value</th>\n",
       "      <th>Four_Bedroom_Median_Typical_Home_Value</th>\n",
       "      <th>...</th>\n",
       "      <th>City_Seattle</th>\n",
       "      <th>City_Stockton</th>\n",
       "      <th>City_Tampa</th>\n",
       "      <th>City_Tucson</th>\n",
       "      <th>City_Tulsa</th>\n",
       "      <th>City_Virginia Beach</th>\n",
       "      <th>City_Washington</th>\n",
       "      <th>City_Wichita</th>\n",
       "      <th>Year</th>\n",
       "      <th>Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>202101</td>\n",
       "      <td>1</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>706417.0</td>\n",
       "      <td>603709.0</td>\n",
       "      <td>751189.0</td>\n",
       "      <td>690397.5</td>\n",
       "      <td>829040.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.000436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>202102</td>\n",
       "      <td>2</td>\n",
       "      <td>California</td>\n",
       "      <td>CA</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>937656.5</td>\n",
       "      <td>575026.0</td>\n",
       "      <td>746089.5</td>\n",
       "      <td>860336.5</td>\n",
       "      <td>1066739.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>202103</td>\n",
       "      <td>3</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>IL</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>282580.0</td>\n",
       "      <td>236544.5</td>\n",
       "      <td>284521.5</td>\n",
       "      <td>291592.0</td>\n",
       "      <td>346520.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.999976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>202104</td>\n",
       "      <td>4</td>\n",
       "      <td>Texas</td>\n",
       "      <td>TX</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>229725.5</td>\n",
       "      <td>132536.0</td>\n",
       "      <td>168663.5</td>\n",
       "      <td>210146.0</td>\n",
       "      <td>276587.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.999956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>202105</td>\n",
       "      <td>5</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>AZ</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>359291.5</td>\n",
       "      <td>216523.0</td>\n",
       "      <td>277632.0</td>\n",
       "      <td>340718.0</td>\n",
       "      <td>428991.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.999978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>202171</td>\n",
       "      <td>71</td>\n",
       "      <td>Nebraska</td>\n",
       "      <td>NE</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>239984.0</td>\n",
       "      <td>202191.0</td>\n",
       "      <td>192750.0</td>\n",
       "      <td>240544.5</td>\n",
       "      <td>326178.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.999982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>202172</td>\n",
       "      <td>72</td>\n",
       "      <td>Texas</td>\n",
       "      <td>TX</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>418720.0</td>\n",
       "      <td>201140.5</td>\n",
       "      <td>291360.0</td>\n",
       "      <td>343630.0</td>\n",
       "      <td>460291.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.999958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>202173</td>\n",
       "      <td>73</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>AK</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>386293.5</td>\n",
       "      <td>182718.5</td>\n",
       "      <td>233835.5</td>\n",
       "      <td>348141.5</td>\n",
       "      <td>439046.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.999957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>202174</td>\n",
       "      <td>74</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>NC</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>314496.5</td>\n",
       "      <td>211638.0</td>\n",
       "      <td>229229.5</td>\n",
       "      <td>292391.5</td>\n",
       "      <td>406237.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.999917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>202175</td>\n",
       "      <td>75</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>NJ</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>569324.0</td>\n",
       "      <td>502310.0</td>\n",
       "      <td>594366.5</td>\n",
       "      <td>585132.5</td>\n",
       "      <td>602130.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.964499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71 rows × 142 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Identifier  City_Rank_by_Population(2021)           State State_abbreviation Observation_Date  Single_Family_Median_Typical_Home_Value  One_Bedroom_Median_Typical_Home_Value  Two_Bedroom_Median_Typical_Home_Value  Three_Bedroom_Median_Typical_Home_Value  Four_Bedroom_Median_Typical_Home_Value  ...  City_Seattle  City_Stockton  City_Tampa  City_Tucson  City_Tulsa  City_Virginia Beach  City_Washington  City_Wichita  Year  Predictions\n",
       "10       202101                              1        New York                 NY       2021-01-01                                 706417.0                               603709.0                               751189.0                                 690397.5                                829040.0  ...           0.0            0.0         0.0          0.0         0.0                  0.0              0.0           0.0  2021     0.000436\n",
       "21       202102                              2      California                 CA       2021-01-01                                 937656.5                               575026.0                               746089.5                                 860336.5                               1066739.5  ...           0.0            0.0         0.0          0.0         0.0                  0.0              0.0           0.0  2021     0.000030\n",
       "32       202103                              3        Illinois                 IL       2021-01-01                                 282580.0                               236544.5                               284521.5                                 291592.0                                346520.0  ...           0.0            0.0         0.0          0.0         0.0                  0.0              0.0           0.0  2021     0.999976\n",
       "43       202104                              4           Texas                 TX       2021-01-01                                 229725.5                               132536.0                               168663.5                                 210146.0                                276587.5  ...           0.0            0.0         0.0          0.0         0.0                  0.0              0.0           0.0  2021     0.999956\n",
       "54       202105                              5         Arizona                 AZ       2021-01-01                                 359291.5                               216523.0                               277632.0                                 340718.0                                428991.5  ...           0.0            0.0         0.0          0.0         0.0                  0.0              0.0           0.0  2021     0.999978\n",
       "..          ...                            ...             ...                ...              ...                                      ...                                    ...                                    ...                                      ...                                     ...  ...           ...            ...         ...          ...         ...                  ...              ...           ...   ...          ...\n",
       "736      202171                             71        Nebraska                 NE       2021-01-01                                 239984.0                               202191.0                               192750.0                                 240544.5                                326178.5  ...           0.0            0.0         0.0          0.0         0.0                  0.0              0.0           0.0  2021     0.999982\n",
       "747      202172                             72           Texas                 TX       2021-01-01                                 418720.0                               201140.5                               291360.0                                 343630.0                                460291.0  ...           0.0            0.0         0.0          0.0         0.0                  0.0              0.0           0.0  2021     0.999958\n",
       "758      202173                             73          Alaska                 AK       2021-01-01                                 386293.5                               182718.5                               233835.5                                 348141.5                                439046.0  ...           0.0            0.0         0.0          0.0         0.0                  0.0              0.0           0.0  2021     0.999957\n",
       "769      202174                             74  North Carolina                 NC       2021-01-01                                 314496.5                               211638.0                               229229.5                                 292391.5                                406237.0  ...           0.0            0.0         0.0          0.0         0.0                  0.0              0.0           0.0  2021     0.999917\n",
       "780      202175                             75      New Jersey                 NJ       2021-01-01                                 569324.0                               502310.0                               594366.5                                 585132.5                                602130.5  ...           0.0            0.0         0.0          0.0         0.0                  0.0              0.0           0.0  2021     0.964499\n",
       "\n",
       "[71 rows x 142 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mattw\\AppData\\Local\\Temp\\ipykernel_29908\\2248695812.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_eval['Predictions'] = np.where(df_eval[\"Predictions\"]>=0.5, 1, 0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    56\n",
       "0    15\n",
       "Name: affordability_home_30yr_Payment_20_Perc_Down, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the raw predicted values to match formatting of actual\n",
    "\n",
    "df_eval['Predictions'] = np.where(df_eval[\"Predictions\"]>=0.5, 1, 0)\n",
    "\n",
    "\n",
    "df_eval['affordability_home_30yr_Payment_20_Perc_Down'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "actual = df_eval['affordability_home_30yr_Payment_20_Perc_Down']\n",
    "predicted = df_eval['Predictions']\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(actual, predicted)\n",
    "\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])\n",
    "\n",
    "cm_display.plot()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Accuracy': 1.0, 'Precision': 1.0, 'Sensitivity_recall': 1.0, 'Specificity': 1.0, 'F1_score': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Metrics Calculation\n",
    "Accuracy = metrics.accuracy_score(actual, predicted)\n",
    "Precision = metrics.precision_score(actual, predicted)\n",
    "Sensitivity_recall = metrics.recall_score(actual, predicted)\n",
    "Specificity = metrics.recall_score(actual, predicted, pos_label=0)\n",
    "F1_score = metrics.f1_score(actual, predicted) \n",
    "\n",
    "print({\"Accuracy\":Accuracy,\"Precision\":Precision,\"Sensitivity_recall\":Sensitivity_recall,\"Specificity\":Specificity,\"F1_score\":F1_score}) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('mlenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "abe6e46539c5d5a879205e2e29e6f71a7d6680463e60cee952a5e80322b7ea19"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
